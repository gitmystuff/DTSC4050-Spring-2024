{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC4050/blob/main/Week_11-Regression_II/Week_11_Regression_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 11: Regression II"
      ],
      "metadata": {
        "id": "OVr8WuT8b1U0"
      },
      "id": "OVr8WuT8b1U0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started\n",
        "\n",
        "* Colab - get notebook from gitmystuff DTSC4050 repository\n",
        "* Save a Copy in Drive\n",
        "* Remove Copy of\n",
        "* Edit name\n",
        "* Take attendance\n",
        "* Clean up Colab Notebooks folder\n",
        "* Submit shared link"
      ],
      "metadata": {
        "id": "uRfFylCjbyMy"
      },
      "id": "uRfFylCjbyMy"
    },
    {
      "cell_type": "markdown",
      "id": "48532040",
      "metadata": {
        "id": "48532040"
      },
      "source": [
        "## Types of Regression\n",
        "\n",
        "* Simple Linear Regression\n",
        "* Multiple Linear Regression\n",
        "* Polynomial Regression\n",
        "* Support Vector Regression\n",
        "* Decision Tree Regression\n",
        "* Random Forest Regression\n",
        "\n",
        "**SEE MORE REGRESSION**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17118446",
      "metadata": {
        "id": "17118446"
      },
      "source": [
        "## Simple Linear Regression\n",
        "\n",
        "In statistics, linear regression is a linear approach for modelling the relationship between a scalar response and one or more explanatory variable (also known as dependent and independent variables). The case of one explanatory variable is called simple linear regression; for more than one, the process is called multiple linear regression. This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Linear_regression\n",
        "\n",
        "### Controlling for Other Factors\n",
        "\n",
        "* Controlling for other factors, holding other factors constant, accounting for other factors, keeping other factors fixed, one unit increase in X1 is, on average, associated with b units increast in y\n",
        "* Example: Income, getting a store credit card, and monthly spending - controlling for income  would compare the average monthly spending with those that get a store credit card and those that don't get a store credit card\n",
        "\n",
        "https://towardsdatascience.com/what-does-it-mean-to-control-for-something-in-multiple-regression-744880620988\n",
        "\n",
        "* Any given experiment has numerous control variables, and it's important for a scientist to try to hold all variables constant except for the independent variable. If a control variable changes during an experiment, it may invalidate the correlation between the dependent and independent variables. When possible, control variables should be identified, measured, and recorded.\n",
        "\n",
        "https://www.thoughtco.com/controlled-variable-definition-609094\n",
        "\n",
        "### Confounding Variables\n",
        "\n",
        "* Confounding Variables: a (third) variable that influences both independent and dependent variables, alcohol and lung cancer (smoking), low blood pressure and mortality (heart disease), ice cream and sunburn (summer sun)\n",
        "* Features of no significance\n",
        "* Lurking variable: An extraneous variable that is not included in statistical analysis, unknown, uncontrolled for, diet soda and traffic accidents (caffeine or population growth)\n",
        "* Ordinary Least Squares: limiting the residual\n",
        "* Relationship models\n",
        "\n",
        "### Hypothesis Testing\n",
        "\n",
        "* To predict future values for the y variable\n",
        "* To infer if the trend is statistically significant\n",
        "\n",
        "This is important to remember because it means that your data does not have to meet the requirements for a linear regression hypothesis test if you are using the regression to predict future values. You need to meet the hypothesis test assumptions if you are trying to determine if there is an actual trend (aka the trend is statistically significant).\n",
        "\n",
        "https://towardsdatascience.com/how-to-simplify-hypothesis-testing-for-linear-regression-in-python-8b43f6917c86\n",
        "\n",
        "For simple linear regression, the chief null hypothesis is H0 : β1 = 0, and the corresponding alternative hypothesis is H1 : β1 = 0. If this null hypothesis is true, then, from E(Y) = β0 + β1x, we can see that the population mean of Y is β0 for every x value, which tells us that x has no effect on Y.\n",
        "\n",
        "https://www.stat.cmu.edu/~hseltman/309/Book/chapter9.pdf\n",
        "\n",
        "### Assumptions\n",
        "\n",
        "* There is a linear regression relation between Y and X\n",
        "* The error terms (residuals) are normally distributed\n",
        "* The variance of the error terms is constant over all X values (homoscedasticity)\n",
        "* The error terms are independent\n",
        "* **ASSUMPTIONS**\n",
        "\n",
        "### Don't Kill When Doing Your Research\n",
        "\n",
        "* https://my.clevelandclinic.org/health/articles/16979-estrogen--hormones\n",
        "* Guard against using explanatory variables that are affected by the outcome of the dependent variable , the outcome we are trying to explain\n",
        "* The explanatory variable should explain the dependent variable not the other way around\n",
        "* Golf and mortality"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Slope Intercept Equation\n",
        "\n",
        "$y = mx + b$\n",
        "\n",
        "$m = \\frac{y_2-y_1}{x_2-x_1} = \\frac{\\Delta y}{\\Delta x} = \\frac{dy}{dx}$\n",
        "\n",
        "* the latter is Leibniz's notation\n",
        "* https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-1-new/ab-2-1/a/derivative-notation-review"
      ],
      "metadata": {
        "id": "cp5ti-wJTLvI"
      },
      "id": "cp5ti-wJTLvI"
    },
    {
      "cell_type": "markdown",
      "id": "2a28391a",
      "metadata": {
        "id": "2a28391a"
      },
      "source": [
        "### The Math\n",
        "\n",
        "$y = mx + b$\n",
        "\n",
        "* $m = \\frac{N * \\sum{(xy)} - \\sum{x}\\sum{y}}{N * \\sum{x^2} - (\\sum{x})^2}$\n",
        "* $b = \\frac{\\sum{y} - m * \\sum{x}}{N}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b5f0d69",
      "metadata": {
        "id": "7b5f0d69",
        "outputId": "1c732494-dd59-4def-faff-cee66ee73d8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   x  y  x^2  xy\n",
            "0  1  1    1   1\n",
            "1  2  3    4   6\n",
            "2  3  2    9   6\n",
            "3  4  3   16  12\n",
            "4  5  5   25  25\n",
            "[15, 14, 55, 50]\n",
            "m: 0.8\n",
            "b: 0.4\n"
          ]
        }
      ],
      "source": [
        "# https://www.mathsisfun.com/data/least-squares-regression.html\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1, 3, 2, 3, 5])\n",
        "\n",
        "def xy(r):\n",
        "    return r.x * r.y\n",
        "\n",
        "m_table = pd.DataFrame({'x': x, 'y': y})\n",
        "m_table['x^2'] = m_table['x'].apply(lambda x: x**2)\n",
        "m_table['xy'] = m_table.apply(xy, axis=1)\n",
        "print(m_table.head())\n",
        "\n",
        "N = len(x)\n",
        "sums = list(m_table.sum())\n",
        "print(sums)\n",
        "m = (N * sums[3] - sums[0] * sums[1]) / (N * sums[2] - sums[0]**2)\n",
        "print('m:', m)\n",
        "b = (sums[1]-m*sums[0])/N\n",
        "print('b:', b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f4e815f",
      "metadata": {
        "id": "7f4e815f"
      },
      "source": [
        "### Correlation vs Simple Linear Regression\n",
        "\n",
        "* A correlation analysis provides information on the strength and direction of the linear relationship between two variables, while a simple linear regression analysis estimates parameters in a linear equation that can be used to predict values of one variable based on the other.\n",
        "* If x and y have the same standard deviation then r equals slope\n",
        "* $y_i = \\alpha + \\beta x_i + \\epsilon_i$\n",
        "* $y = \\alpha + \\beta x$\n",
        "\n",
        "The parameters for linear regression are $\\alpha$ and $\\beta$ and $e$. The error term, $e$, represents the rest of $y$ that $X$ cannot explain. If we look at $y = f(X) + e$ and assume that the function of $e$ is iid, then the sum of $e$ will be zero and is usually left off of the equation.\n",
        "\n",
        "The sum of the residuals always equals zero (assuming that your line is actually the line of 'best fit...' The mean of residuals is also equal to zero, as the mean = the sum of the residuals / the number of items. The sum is zero, so 0/n will always equal zero.\n",
        "\n",
        "Stephanie Glen. \"Residual Values (Residuals) in Regression Analysis\" From StatisticsHowTo.com: Elementary Statistics for the rest of us! https://www.statisticshowto.com/residual/\n",
        "\n",
        "* $\\hat{\\alpha} = \\bar{y} - (\\hat{\\beta}\\bar{x})$\n",
        "* $\\hat{\\beta} = \\frac{\\sum^N_{i=1}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum^N_{i=1}(x_i - \\bar{x})^2}$\n",
        "* $ = \\frac{s_{xy}}{s^2_x}$\n",
        "* $ = r_{xy}\\frac{s_y}{s_x}$\n",
        "* $ r_{xy} = \\frac{cov(x,y)}{\\sigma_x\\sigma_y} = \\frac{\\frac{1}{N}\\sum(x-\\bar{x})(y-\\bar{y})}{\\sqrt\\frac{\\sum(x-\\bar{x})^2}{N}\\sqrt\\frac{\\sum(y-\\bar{y})^2}{N}}  = \\frac{\\sum(x-\\bar{x})(y-\\bar{y})}{\\sqrt{\\sum(x-\\bar{x})^2}\\sqrt{\\sum(y-\\bar{y})^2}}$\n",
        "\n",
        "where\n",
        "\n",
        "* $\\bar{x}$ and $\\bar{y}$ as the average of $x_i$ and $y_i$, respectively\n",
        "* $r_{xy}$ is the **sample correlation coefficient** between x and y\n",
        "* $s_x$ and $s_y$ is the **uncorrected sample standard deviations** of x and y\n",
        "* $s_{x}^2$ and $s_{x,y}$ is the **sample variance** and **sample covariance**, respectively\n",
        "\n",
        "**Sample Correlation Coefficient**: In statistics, correlation or dependence is any statistical relationship, whether causal or not, between two random variables or bivariate data. Although in the broadest sense, \"correlation\" may indicate any type of association, in statistics it normally refers to the degree to which a pair of variables are linearly related. The sample correlation coefficient can be used to estimate the population Pearson correlation\n",
        "\n",
        "https://en.wikipedia.org/wiki/Correlation#Sample_correlation_coefficient\n",
        "\n",
        "**Uncorrected Sample Standard Deviation**: In statistics, the standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range. The formula for the population standard deviation (of a finite population) can be applied to the sample, using the size of the sample as the size of the population (though the actual population size from which the sample is drawn may be much larger). This estimator, denoted by sN, is known as the uncorrected sample standard deviation, or sometimes the standard deviation of the sample (considered as the entire population), and is defined as follows:\n",
        "\n",
        "$s_N = \\sqrt{\\frac{1}{N}\\sum{(x-\\bar{x})^2}}$\n",
        "\n",
        "https://en.wikipedia.org/wiki/Standard_deviation#Uncorrected_sample_standard_deviation\n",
        "\n",
        "### Residuals\n",
        "\n",
        "https://www.statology.org/residual-sum-of-squares-in-excel/\n",
        "\n",
        "### Bias\n",
        "\n",
        "According to Wikipedia (2022):\n",
        "\n",
        "In statistics, Bessel's correction is the use of n − 1 instead of n in the formula for the sample variance and sample standard deviation, where n is the number of observations in a sample. This method corrects the bias in the estimation of the population variance. It also partially corrects the bias in the estimation of the population standard deviation. However, the correction often increases the mean squared error in these estimations. This technique is named after Friedrich Bessel (para 1).\n",
        "\n",
        "Bessel's correction. (June 13, 2022). In *Wikipedia*. https://en.wikipedia.org/wiki/Bessel%27s_correction\n",
        "\n",
        "* What is bias? https://stats.libretexts.org/Bookshelves/Applied_Statistics/Book%3A_Answering_Questions_with_Data_-__Introductory_Statistics_for_Psychology_Students_(Crump)/04%3A_Probability_Sampling_and_Estimation/4.13%3A_Estimating_population_parameters\n",
        "* What are degrees of freedom? https://www.statisticshowto.com/probability-and-statistics/hypothesis-testing/degrees-of-freedom/\n",
        "\n",
        "### Biased\n",
        "\n",
        "**Standard Deviation of the Population**: $\\sigma = \\sqrt{\\frac{1}{N}\\sum(x-\\bar{x})^2}$\n",
        "\n",
        "**Uncorrected Sample Standard Deviation**: $sN = \\sqrt{\\frac{1}{N}\\sum(x-\\bar{x})^2}$\n",
        "\n",
        "### Unbiased\n",
        "\n",
        "**Standard Deviation of the Sample**: $s = \\sqrt{\\frac{1}{n-1}\\sum(x-\\bar{x})^2}$\n",
        "\n",
        "**SEE BESSEL'S CORRECTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14a38ea7",
      "metadata": {
        "id": "14a38ea7"
      },
      "source": [
        "### Linear Interpolation\n",
        "\n",
        "a type of estimation, a method of constructing (finding) new data points based on the range of a discrete set of known data points.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Interpolation\n",
        "\n",
        "linear interpolation is a method of curve fitting using linear polynomials to construct new data points within the range of a discrete set of known data points\n",
        "\n",
        "https://en.wikipedia.org/wiki/Linear_interpolation\n",
        "\n",
        "$y = y_0 + (x - x_0) \\frac{y_1-y_0}{x_1-x_0}$\n",
        "\n",
        "### Line of Best Fit\n",
        "\n",
        "$y = \\alpha + \\beta x$\n",
        "\n",
        "The following plots the line of best fit. We'll break it down using the formulas for $\\widehat{\\alpha }$ and $\\widehat{\\beta}$. The points are plotted along with the line of best fit. The red lines indicate how much error there is with the actual values (the green points) and the predicted values (the black points) that forms the line of best fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d64c98",
      "metadata": {
        "id": "e1d64c98",
        "outputId": "af9b6cac-4ac9-4843-ae40-288395408c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a= 0.4 b= 0.8\n",
            "x values: [1 2 3 4 5]\n",
            "y values: [1 3 2 3 5]\n",
            "predicted values: [1.2, 2.0, 2.8, 3.6, 4.4]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot x, y coordinates\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1, 3, 2, 3, 5])\n",
        "\n",
        "# create basic scatterplot\n",
        "plt.plot(x, y, 'go',)\n",
        "\n",
        "# obtain a and b of linear regression line\n",
        "b, a = np.polyfit(x, y, 1)\n",
        "print('a=', a.round(1), 'b=', b.round(1))\n",
        "\n",
        "# predicted values\n",
        "y_hat = [round(a + (b*x), 2) for x in x]\n",
        "print(f'x values: {x}')\n",
        "print(f'y values: {y}')\n",
        "print(f'predicted values: {y_hat}')\n",
        "plt.plot(x, y_hat, 'ko')\n",
        "\n",
        "# add linear regression line to scatterplot\n",
        "plt.plot(x, a+b*x, 'b')\n",
        "\n",
        "# ax.vlines(x,y,y)\n",
        "plt.vlines(x, y, a+b*x, 'r')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94750343",
      "metadata": {
        "id": "94750343"
      },
      "source": [
        "Let's do some math and solve for $\\beta$ using the formula\n",
        "\n",
        "$\\widehat{\\beta} = \\frac{s_{x,y}}{s^2_x} = r_{xy}\\frac{s_y}{s_x} = \\frac{\\sum{(x - \\bar{x})(y - \\bar{y})}}{\\sum(x - \\bar{x})^2}$\n",
        "\n",
        "where:\n",
        "* $\\bar{x}$ and $\\bar{y}$ are the averages of x and y\n",
        "* $r_{xy}$ is the sample variance\n",
        "* $s_x$ and $s_y$ are the sample standard deviation (uncorrected)\n",
        "* $s_{x,y}$ and $s^2_x$ are the sample variance and sample covariance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf5e92c2",
      "metadata": {
        "id": "bf5e92c2",
        "outputId": "b9c26e69-d930-40d5-93a3-cd5598ca4636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# our data\n",
        "X = [1, 2, 3, 4, 5]\n",
        "\n",
        "# find the mean of X\n",
        "# x_mean = (1 + 2 + 3 + 4 + 5) / 5 or using list comprehension\n",
        "x_mean = sum(i for i in x) / len(x)\n",
        "\n",
        "#print x_mean\n",
        "x_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aec0412",
      "metadata": {
        "id": "6aec0412",
        "outputId": "07e8fe80-b8cd-4f95-e416-88f5a961d25f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# print the mean of y\n",
        "y = [1, 3, 2, 3, 5]\n",
        "y_mean = sum(i for i in y) / len(y)\n",
        "y_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de7da0f",
      "metadata": {
        "id": "0de7da0f"
      },
      "source": [
        "Recall the $\\beta$ formula according to Wikipedia\n",
        "\n",
        "$\\widehat{\\beta} = \\frac{\\sum{(x - \\bar{x})(y - \\bar{y})}}{\\sum(x - \\bar{x})^2}$\n",
        "\n",
        "So, solving for the numerator of $\\widehat{\\beta}$ we would use: $\\sum(x-\\bar{x})(y-\\bar{y})$\n",
        "\n",
        "Since the dataset is small we can do something like this: <br />\n",
        "((1 - 3) * (1 - 2.8)) +<br />\n",
        "((2 - 3) * (3 - 2.8)) +<br />\n",
        "((3 - 3) * (2 - 2.8)) +<br />\n",
        "((4 - 3) * (3 - 2.8)) +<br />\n",
        "((5 - 3) * (5 - 2.8)) = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "800fdba6",
      "metadata": {
        "id": "800fdba6",
        "outputId": "473fc8ac-de72-4a86-d972-fa4ba6ecd88e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# print the numerator the pythonic way\n",
        "numerator = sum([(i - x_mean) * (j - y_mean) for i, j in zip(x, y)])\n",
        "numerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6395afd3",
      "metadata": {
        "id": "6395afd3"
      },
      "source": [
        "Recall the $\\beta$ formula according to Wikipedia\n",
        "\n",
        "$\\widehat{\\beta} = \\frac{\\sum{(x - \\bar{x})(y - \\bar{y})}}{\\sum(x - \\bar{x})^2}$\n",
        "\n",
        "So, solving for the denominator of $\\widehat{\\beta}$ we would use: $\\sum(x - \\bar{x})^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c38a2037",
      "metadata": {
        "id": "c38a2037",
        "outputId": "5d03d314-8959-4346-d053-2a8da32a4814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# get the denominator\n",
        "denominator = sum((i - x_mean)**2 for i in x)\n",
        "denominator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8c68bb0",
      "metadata": {
        "id": "c8c68bb0"
      },
      "source": [
        "So, $\\beta$, or specifically $\\widehat{\\beta}$, is equal to the numerator divided by the denominator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a003ad9",
      "metadata": {
        "id": "1a003ad9",
        "outputId": "dc280d9a-d400-4fa4-fbd1-a023d348cd66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "beta = numerator / denominator\n",
        "beta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "057dd937",
      "metadata": {
        "id": "057dd937"
      },
      "source": [
        "To find $\\alpha$ we use the formula $\\widehat{\\alpha} = \\bar{y} - \\beta \\bar{x}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5021be7",
      "metadata": {
        "id": "d5021be7",
        "outputId": "ae626da0-5cd8-4874-d018-b83c1297cdfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# calculate alpha\n",
        "alpha = round(y_mean - (beta * x_mean), 2)\n",
        "alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8a84f83",
      "metadata": {
        "id": "b8a84f83"
      },
      "source": [
        "$y = a + \\beta X$\n",
        "\n",
        "Our linear regression equation is solved: <br />\n",
        "y = 0.4 + 0.8(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5658481",
      "metadata": {
        "id": "c5658481"
      },
      "source": [
        "## Least Squares\n",
        "\n",
        "The method of least squares is a standard approach in regression analysis to approximate the solution of overdetermined systems (sets of equations in which there are more equations than unknowns) by minimizing the sum of the squares of the residuals (a residual being: the difference between an observed value, and the fitted value provided by a model) made in the results of each individual equation.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Least_squares\n",
        "\n",
        "### The Constant\n",
        "\n",
        "In linear regression you need that constants to have lines which are not constrained to pass through origin. Think of linear model y=b1x1+b2x2+.... If all xi are 0, y must be 0, you need an additional parameter to pass that constraint\n",
        "\n",
        "https://datascience.stackexchange.com/questions/55598/why-we-add-a-constant-value-column-in-our-dataframe-sometimes\n",
        "\n",
        "... our regression slopes would be less useful (without the constant).\n",
        "\n",
        "1. Imagine the equation for a line: y=mx + b -> take the constant out and you have y=mx which means that the slope will have to account for a larger explanation than with the constant.\n",
        "2. think of the constant as the “baseline” of the data and the explanatory values (the beta slopes) as the things that can affect this mean. For example, ...suppose a particular leaf will average 2 inches long (constant), but with different weather conditions, the leaf will either grow (+ length) or grow (- length). Without the constant, all the data will point to the weather conditions having a tremendous weight on the regressions - mathematically showing y = weather conditions times slope.\n",
        "\n",
        "In a nut shell, it’s there to assist in providing an accurate view of the slope values.\n",
        "\n",
        "https://www.quora.com/In-regression-why-do-we-include-a-constant-term (Hamilton Goff)\n",
        "\n",
        "The constant term prevents this overall bias by forcing the residual mean to equal zero. Imagine that you can move the regression line up or down to the point where the residual mean equals zero. For example, if the regression produces residuals with a positive average, just move the line up until the mean equals zero.\n",
        "\n",
        "https://statisticsbyjim.com/regression/interpret-constant-y-intercept-regression/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03333762",
      "metadata": {
        "id": "03333762",
        "outputId": "bc17d41d-d2c5-4656-b0b1-8dba92701f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = 0.4 + 0.8(X)\n"
          ]
        }
      ],
      "source": [
        "# using scipy\n",
        "import scipy.stats as stats\n",
        "\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1, 3, 2, 3, 5])\n",
        "\n",
        "model = stats.linregress(x, y)\n",
        "\n",
        "plt.plot(x, y, 'go', label='original data')\n",
        "plt.plot(x, model.intercept + model.slope*x, 'b', label='fitted line')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f'y = {model.intercept:.2} + {model.slope:.2}(X)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5159157e",
      "metadata": {
        "id": "5159157e",
        "outputId": "0b8ba435-c3ef-4432-d964-5ce8df02d601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = 0.4 + 0.8X\n"
          ]
        }
      ],
      "source": [
        "# use numpy linear algebra least squares\n",
        "import numpy as np\n",
        "\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1, 3, 2, 3, 5])\n",
        "\n",
        "x = np.vstack([np.ones(len(x)), x]).T\n",
        "a, b = np.linalg.lstsq(x, y, rcond=None)[0]\n",
        "print(f'y = {a:0.1f} + {b:0.1f}X')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8c0ce75",
      "metadata": {
        "id": "f8c0ce75"
      },
      "source": [
        "## Linear Regression with Scikit-learn\n",
        "\n",
        "Scikit-learn (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Scikit-learn\n",
        "\n",
        "As mentioned, Scikit-learn provides us with a linear regression model that we can use as demonstrated in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ba706b",
      "metadata": {
        "id": "c1ba706b",
        "outputId": "5405aa77-5579-4b37-f9af-844f6604b1d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = 0.4 + 0.8(X)\n"
          ]
        }
      ],
      "source": [
        "# using sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1, 3, 2, 3, 5])\n",
        "x = x.reshape(-1, 1)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(x, y)\n",
        "print(f'y = {model.intercept_:.2} + {model.coef_[0]:.2}(X)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747b9656",
      "metadata": {
        "id": "747b9656"
      },
      "source": [
        "## Linear Algebra\n",
        "\n",
        "* $y_i = \\theta^TX_i + \\epsilon_i$\n",
        "* $h_\\theta(x) = \\theta_0 + \\theta_1x_1$\n",
        "* $\\theta = (X^T * X)^{-1} * X^T * y$\n",
        "* Dot product - https://en.wikipedia.org/wiki/Dot_product\n",
        "* Inverse - https://www.mathsisfun.com/algebra/matrix-inverse.html\n",
        "* To multiply an m×n matrix by an n×p matrix, the ns must be the same,\n",
        "and the result is an m×p matrix.\n",
        "\n",
        "https://towardsdatascience.com/performing-linear-regression-using-the-normal-equation-6372ed3c57\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21aa8502",
      "metadata": {
        "id": "21aa8502"
      },
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "In mathematics, particularly in linear algebra, matrix multiplication is a binary operation that produces a matrix from two matrices. For matrix multiplication, the number of columns in the first matrix must be equal to the number of rows in the second matrix. The resulting matrix, known as the matrix product, has the number of rows of the first and the number of columns of the second matrix. The product of matrices A and B is denoted as AB.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Matrix_multiplication\n",
        "\n",
        "m = rows; n = columns; (m, n) can be multiplied with another (m, n) if n from first matrix is equal to m for second matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba53c59",
      "metadata": {
        "id": "1ba53c59",
        "outputId": "dfa20bf1-a362-4465-ae67-40bc8a58267f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Let's look at the x data\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5196da57",
      "metadata": {
        "id": "5196da57",
        "outputId": "c5a49299-e3ea-41af-f706-2f7394dd6651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Look at the y data\n",
        "y = np.array([1, 3, 2, 3, 5])\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbfc5a0f",
      "metadata": {
        "id": "cbfc5a0f"
      },
      "source": [
        "To be able to multiply two matrices, the number of columns in the first matrix must equal the number of rows in the second matrix (array)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5e27cc",
      "metadata": {
        "id": "5a5e27cc",
        "outputId": "caadbe2a-f5df-468f-a744-796994d68ea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4],\n",
              "       [5]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Reshape x so that the columns in x equals the number of rows in y\n",
        "x = x.reshape(-1, 1)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b3b3b57",
      "metadata": {
        "id": "9b3b3b57",
        "outputId": "946731bd-48cd-4c1f-c351-ba33a94d6886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]]\n",
            "[1 3 2 3 5]\n",
            "\n",
            "x matrix\n",
            "[[1 1]\n",
            " [1 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [1 5]]\n",
            "\n",
            "[[1 1 1 1 1]\n",
            " [1 2 3 4 5]]\n",
            "[[1 1]\n",
            " [1 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [1 5]]\n",
            "[1, 1, 1, 1, 1] * [1, 1, 1, 1, 1] = 5\n",
            "[1, 1, 1, 1, 1] * [1, 2, 3, 4, 5] = 15\n",
            "[1, 2, 3, 4, 5] * [1, 1, 1, 1, 1] = 15\n",
            "[1, 2, 3, 4, 5] * [1, 2, 3, 4, 5] = 55\n",
            "\n",
            "x.T.dot(x)\n",
            "[[ 5 15]\n",
            " [15 55]]\n",
            "\n",
            "inverse\n",
            "[[ 55 -15]\n",
            " [-15   5]]\n",
            "1/(5*55 - 15*15) * x.T.dot(x) where a and d are swapped and b and c are negative = 1/(275-225) = 1/50\n",
            "\n",
            "[[ 1.1 -0.3]\n",
            " [-0.3  0.1]]\n",
            "[[1 1 1 1 1]\n",
            " [1 2 3 4 5]]\n",
            "[[ 0.8  0.5  0.2 -0.1 -0.4]\n",
            " [-0.2 -0.1  0.   0.1  0.2]]\n",
            "\n",
            "dot(y)\n",
            "[[ 0.8  0.5  0.2 -0.1 -0.4]\n",
            " [-0.2 -0.1  0.   0.1  0.2]]\n",
            "[1 3 2 3 5]\n",
            "[0.8, 0.5, 0.2, -0.1, -0.4] * [1, 3, 2, 3, 5] = .8 + 1.5 + .4 - .3 - 2 = .4\n",
            "[-0.2, -0.1, 0, 0.1, 0.2] * [1, 3, 2, 3, 5] = -.2 - .3 + 0 + .3 + 1 = .8\n",
            "[0.4 0.8]\n",
            "\n",
            "weights =  [0.4 0.8]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1, 3, 2, 3, 5])\n",
        "x = x.reshape(-1, 1)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print()\n",
        "\n",
        "x = np.append(arr = np.ones((5, 1)).astype(int), values = x, axis = 1)\n",
        "print('x matrix')\n",
        "print(x)\n",
        "print()\n",
        "\n",
        "print(x.T)\n",
        "print(x)\n",
        "print('[1, 1, 1, 1, 1] * [1, 1, 1, 1, 1] = 5')\n",
        "print('[1, 1, 1, 1, 1] * [1, 2, 3, 4, 5] = 15')\n",
        "print('[1, 2, 3, 4, 5] * [1, 1, 1, 1, 1] = 15')\n",
        "print('[1, 2, 3, 4, 5] * [1, 2, 3, 4, 5] = 55')\n",
        "print()\n",
        "\n",
        "print('x.T.dot(x)')\n",
        "print(x.T.dot(x))\n",
        "print()\n",
        "\n",
        "print('inverse')\n",
        "print(np.array([[55, -15], [-15, 5]]))\n",
        "print('1/(5*55 - 15*15) * x.T.dot(x) where a and d are swapped and b and c are negative = 1/(275-225) = 1/50')\n",
        "print()\n",
        "\n",
        "print(np.linalg.inv(x.T.dot(x)))\n",
        "print(x.T)\n",
        "wy = np.linalg.inv(x.T.dot(x)).dot(x.T)\n",
        "print(wy)\n",
        "print()\n",
        "print('dot(y)')\n",
        "print(wy)\n",
        "print(y)\n",
        "print('[0.8, 0.5, 0.2, -0.1, -0.4] * [1, 3, 2, 3, 5] = .8 + 1.5 + .4 - .3 - 2 = .4')\n",
        "print('[-0.2, -0.1, 0, 0.1, 0.2] * [1, 3, 2, 3, 5] = -.2 - .3 + 0 + .3 + 1 = .8')\n",
        "print(wy.dot(y))\n",
        "print()\n",
        "print('weights = ', np.linalg.inv(x.T.dot(x)).dot(x.T).dot(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bdf60d9",
      "metadata": {
        "id": "2bdf60d9"
      },
      "source": [
        "### Why Matrix Multiplication?\n",
        "\n",
        "Linear algebra is often used in data science / machine learning which includes matrix multiplication. To stay within the scope of this course we will simply say that because of the large number of features that X can potentially represent, it is more efficient to use matrix multiplication.\n",
        "\n",
        "Because matrix multiplication is such a central operation in many numerical algorithms, much work has been invested in making matrix multiplication algorithms efficient. Applications of matrix multiplication in computational problems are found in many fields including scientific computing and pattern recognition and in seemingly unrelated problems such as counting the paths through a graph.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm\n",
        "\n",
        "Please review the following links to learn more:\n",
        "\n",
        "* https://en.wikipedia.org/wiki/Linear_algebra\n",
        "* https://online.stat.psu.edu/stat462/node/132/\n",
        "* https://www.mathsisfun.com/algebra/matrix-multiplying.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Derivative\n",
        "\n",
        "The derivative is a fundamental tool of calculus that quantifies the sensitivity of change of a function's output with respect to its input. The derivative of a function of a single variable at a chosen input value, when it exists, is the slope of the tangent line to the graph of the function at that point. The tangent line is the best linear approximation of the function near that input value. For this reason, the derivative is often described as the instantaneous rate of change, the ratio of the instantaneous change in the dependent variable to that of the independent variable.[1] The process of finding a derivative is called differentiation.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Derivative\n",
        "\n",
        "A partial derivative of a function of several variables is its derivative with respect to one of those variables, with the others held constant (as opposed to the total derivative, in which all variables are allowed to vary). Partial derivatives are used in vector calculus and differential geometry.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Partial_derivative\n",
        "\n",
        "* We find the derivative of a function using the Power Rule\n",
        "* The derivative of $f(x) = x^2$ is $f'(x) = 2x$\n",
        "* The partial derivative of $f(x, y) = x^2 + y^3$ is $f'(x) = 2x + 0 = 2x$\n",
        "* In this case we find the partial derivative with respect to x and hold y as a constant\n",
        "* The derivative of a constant is 0\n",
        "\n",
        "https://www.mathsisfun.com/calculus/derivatives-partial.html\n",
        "\n",
        "* **Gradient Descent**"
      ],
      "metadata": {
        "id": "uM25rCZJx_73"
      },
      "id": "uM25rCZJx_73"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Astronomy\n",
        "\n"
      ],
      "metadata": {
        "id": "mmYgp61luJ8s"
      },
      "id": "mmYgp61luJ8s"
    },
    {
      "cell_type": "markdown",
      "id": "e628248c",
      "metadata": {
        "id": "e628248c"
      },
      "source": [
        "## Multiple Linear Regression\n",
        "\n",
        "https://www.investopedia.com/terms/m/mlr.asp\n",
        "\n",
        "$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 ... + \\beta_n x_n + \\epsilon$\n",
        "\n",
        "where:\n",
        "* y = dependent variable\n",
        "* x = explanatory  variable\n",
        "* $\\beta_0$ = intercept\n",
        "* $\\beta_n$ = slope coefficients\n",
        "* $\\epsilon$ = the model's error term\n",
        "\n",
        "### Confounding Variables\n",
        "\n",
        "* https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_multivariable/bs704_multivariable7.html\n",
        "\n",
        "### Closed Form\n",
        "\n",
        "* http://faculty.cas.usf.edu/mbrannick/regression/Part3/Reg2.html\n",
        "\n",
        "### Assumptions of Linear Regression\n",
        "\n",
        "* Linearity: There is a linear relationship between the independent variable and the dependent variable\n",
        "* No Multicollinearity: Features should not be highly correlated\n",
        "* Normality: The residuals are normally distributed\n",
        "* Homoscedasticity: The residuals have an even distribution around the mean and across the spread\n",
        "* Independence: There is no correlation between residuals; there is no trend, no pattern, no structure in residuals\n",
        "* Time series may violate independence\n",
        "* Elements that are randomly assigned to features may violate independence\n",
        "* All relevant explanatory variables must be used\n",
        "* Features cannot be correlated with error term\n",
        "\n",
        "Become familiar with the plots provided in the following links:\n",
        "* https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/\n",
        "* https://www.jmp.com/en_us/statistics-knowledge-portal/what-is-regression/simple-linear-regression-assumptions.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mario Kart"
      ],
      "metadata": {
        "id": "v16tw3gTfyhb"
      },
      "id": "v16tw3gTfyhb"
    },
    {
      "cell_type": "markdown",
      "id": "392210be",
      "metadata": {
        "id": "392210be"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "! git clone https://github.com/GithubName/ProjectName.git\n",
        "</pre>\n",
        "\n",
        "<pre>\n",
        "import pandas as pd\n",
        "from dtsc4050.version import __version__\n",
        "import dtsc4050.utils as utils\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/gitmystuff/Datasets/main/mariokart.csv', index_col=0)\n",
        "\n",
        "print(__version__)\n",
        "print(utils.functions.hello_4050())\n",
        "print(utils.functions.identify_consts(df))\n",
        "print(utils.functions.identify_quasi_consts(df))\n",
        "print(utils.functions.check_row_duplicates(df))\n",
        "print(utils.functions.check_col_duplicates(df))\n",
        "</pre>\n",
        "\n",
        "* Initialize git\n",
        "* .gitignore - https://ask.replit.com/t/how-to-move-replit-to-github-this-is-the-step/92373\n",
        "* In Replit, drop Git tab down and look for Create Repository...\n"
      ],
      "metadata": {
        "id": "QyAmWiTeC8l_"
      },
      "id": "QyAmWiTeC8l_"
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import random\n",
        "# import re\n",
        "# from sklearn.datasets import make_regression\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def make_null(r, w):\n",
        "#     rtn = random.choices([np.nan, r], weights=[w, 100-w])\n",
        "#     return re.sub(r\"[\\[\\]]\",'', str(rtn))\n",
        "\n",
        "# X, y = make_regression(n_samples=100, n_features=10, n_informative=6)\n",
        "# cols = ['Wiggler', 'Lakito', 'Tanooki Mario', 'Dry Bones', 'Lemmy Koopa', 'Toadette', 'Wario', 'Cat Peach', 'King Boo', 'Inkling', 'Baby Daisy', 'Luigi', 'Toad', 'Yoshi', 'Bowser', 'Donkey Kong', 'Princess Peach', 'Isabelle', 'Koopa Troopa', 'Mario', 'Chain Chomp', 'MII', 'Birdo', 'Baby Mario']\n",
        "# random.shuffle(cols)\n",
        "# variables = cols[:10]\n",
        "# df = pd.DataFrame(data=X, columns=variables)\n",
        "# print(df.info())\n",
        "# print(cols[10])\n",
        "# df[cols[10]] = round(df[cols[0]], 4)\n",
        "# df[cols[11]] = df[cols[0]]\n",
        "# df[cols[12]] = 0.03\n",
        "# df[cols[13]] = 0.07\n",
        "\n",
        "# df[cols[14]] = np.random.normal(0, 1, 100)\n",
        "# df[cols[15]] = np.random.normal(0, 1, 100)\n",
        "# df[cols[16]] = np.random.normal(0, 1, 100)\n",
        "\n",
        "# df[cols[14]] = df[cols[14]].apply(lambda r: abs(r) if (r < -0.02) else r)\n",
        "# df[cols[15]] = df[cols[15]].apply(lambda r: abs(r)*-1 if (r > 0.01) else r)\n",
        "# df[cols[16]] = df[cols[16]].apply(lambda r: abs(r) if (r < -0.01) else r)\n",
        "\n",
        "# cats = [random.choice(['fast', 'medium', 'slow']) for i in range(100)]\n",
        "# df[cols[17]] = cats\n",
        "# cats = [random.choice(['disagree', 'kind of disagree', 'neutral', 'kind of agree', 'agree']) for i in range(100)]\n",
        "# df[cols[18]] = cats\n",
        "# cats = [random.choice(['yes', 'no']) for i in range(100)]\n",
        "# df[cols[19]] = cats\n",
        "# cats = [random.choice(['up', 'down']) for i in range(100)]\n",
        "# df[cols[20]] = cats\n",
        "\n",
        "# df[cols[21]] = random.sample(range(10000, 30000), 100)\n",
        "# df[cols[22]] = random.sample(range(1000, 3000), 100)\n",
        "# df[cols[21]] = df[cols[21]].apply(make_null, args=(2,))\n",
        "# df[cols[22]] = df[cols[22]].apply(make_null, args=(2,))\n",
        "\n",
        "# df['Mario Kart'] = y\n",
        "\n",
        "# dupes = df.loc[0:7]\n",
        "# df = df.append(dupes, ignore_index = True)\n",
        "# df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# # df.to_csv('mariokart.csv')\n",
        "\n",
        "# print(df.shape)\n",
        "# print(df.info())\n",
        "# df.head()"
      ],
      "metadata": {
        "id": "x2UR9NByHZWs"
      },
      "id": "x2UR9NByHZWs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dab62915",
      "metadata": {
        "id": "dab62915"
      },
      "outputs": [],
      "source": [
        "# # get data\n",
        "# import pandas as pd\n",
        "\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/gitmystuff/Datasets/main/mariokart.csv', index_col=0)\n",
        "# print(df.shape)\n",
        "# print(df.info())\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d34d69e2",
      "metadata": {
        "id": "d34d69e2"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b37e55",
      "metadata": {
        "id": "09b37e55"
      },
      "outputs": [],
      "source": [
        "# # replace missing values and then check how many unique values are in each variable\n",
        "# few_values = [\n",
        "#     val for val in df.columns if len(df[val].fillna(0).unique()) == 1\n",
        "# ]\n",
        "\n",
        "# few_values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ca36293",
      "metadata": {
        "id": "7ca36293"
      },
      "source": [
        "### Quasi Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a2898d",
      "metadata": {
        "id": "e5a2898d"
      },
      "outputs": [],
      "source": [
        "# # quasi constant values (sometimes these may be boolean features)\n",
        "# for val in df.columns.sort_values():\n",
        "#     if (len(df[val].unique()) < 3):\n",
        "#         print(df[val].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10dbfa47",
      "metadata": {
        "id": "10dbfa47"
      },
      "source": [
        "### Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e84f7dec",
      "metadata": {
        "id": "e84f7dec"
      },
      "outputs": [],
      "source": [
        "# # duplicate rows\n",
        "# df[df.duplicated(keep=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54e22e51",
      "metadata": {
        "id": "54e22e51"
      },
      "outputs": [],
      "source": [
        "# # drop duplicate rows\n",
        "# df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a902121b",
      "metadata": {
        "id": "a902121b"
      },
      "outputs": [],
      "source": [
        "# # check of duplicate columns\n",
        "# duplicate_features = []\n",
        "# for i in range(0, len(df.columns)):\n",
        "#     orig = df.columns[i]\n",
        "\n",
        "#     for dupe in df.columns[i + 1:]:\n",
        "#         if df[orig].equals(df[dupe]):\n",
        "#             duplicate_features.append(dupe)\n",
        "#             print(f'{orig} looks the same as {dupe}')\n",
        "\n",
        "# duplicate_features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "870b5c37",
      "metadata": {
        "id": "870b5c37"
      },
      "source": [
        "### Drop Weak Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad28284",
      "metadata": {
        "id": "fad28284"
      },
      "outputs": [],
      "source": [
        "# # drop the variables that are duplicated or low in variance\n",
        "# df.drop(['Luigi', 'Baby Mario', 'Birdo'], axis=1, inplace=True)\n",
        "# df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8886e5c5",
      "metadata": {
        "id": "8886e5c5"
      },
      "source": [
        "### Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a350ea4",
      "metadata": {
        "id": "5a350ea4"
      },
      "outputs": [],
      "source": [
        "# # check for nulls\n",
        "# df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176f15aa",
      "metadata": {
        "id": "176f15aa"
      },
      "outputs": [],
      "source": [
        "# # look at the shape of variables that are numerical\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# df.hist()\n",
        "# plt.tight_layout();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57107293",
      "metadata": {
        "id": "57107293"
      },
      "outputs": [],
      "source": [
        "# # impute missing values with mean and median\n",
        "# df['Toad'].fillna(round(df['Toad'].mean(), 2), inplace=True)\n",
        "# df['Koopa Troopa'].fillna(round(df['Koopa Troopa'].mean(), 2), inplace=True)\n",
        "# df['Bowser'].fillna(round(df['Bowser'].mean(), 2), inplace=True)\n",
        "# df['Donkey Kong'].fillna(df['Donkey Kong'].median(), inplace=True)\n",
        "# df['Princess Peach'].fillna(df['Princess Peach'].median(), inplace=True)\n",
        "# df['Isabelle'].fillna(df['Isabelle'].median(), inplace=True)\n",
        "# df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e06040",
      "metadata": {
        "id": "f3e06040"
      },
      "outputs": [],
      "source": [
        "# # impute missing values with mode\n",
        "# print(df['Wario'].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec4b1cd",
      "metadata": {
        "id": "bec4b1cd"
      },
      "outputs": [],
      "source": [
        "# # replace work_status with mode (not employed)\n",
        "# df['Wario'].fillna(df['Wario'].mode()[0], inplace=True)\n",
        "# df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6138e07",
      "metadata": {
        "id": "d6138e07"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28979deb",
      "metadata": {
        "id": "28979deb"
      },
      "outputs": [],
      "source": [
        "# # train test split\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df.drop(['Mario Kart'], axis=1), df['Mario Kart'], test_size=.2, random_state=42)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9bdbd25",
      "metadata": {
        "id": "f9bdbd25"
      },
      "source": [
        "### Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1be2d1fd",
      "metadata": {
        "id": "1be2d1fd"
      },
      "outputs": [],
      "source": [
        "# # quartiles\n",
        "# for feat in X_train._get_numeric_data().columns[1:]:\n",
        "#     q1 = X_train[feat].quantile(0.25)\n",
        "#     q3 = X_train[feat].quantile(0.75)\n",
        "#     iqr = q3 - q1\n",
        "#     lower_fence = (q1 - 1.5 * iqr)\n",
        "#     upper_fence = (q3 + 1.5 * iqr)\n",
        "#     lower_count = X_train[feat][X_train[feat] < lower_fence].count()\n",
        "#     upper_count = X_train[feat][X_train[feat] > upper_fence].count()\n",
        "#     print(f'{feat} outliers = {lower_count + upper_count}: lower_fence: {lower_fence}, upper_fence: {upper_fence}, lower_count: {lower_count}, upper_count: {upper_count}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44d4de39",
      "metadata": {
        "id": "44d4de39"
      },
      "outputs": [],
      "source": [
        "# # Assignment boxplot\n",
        "# X_train.boxplot(column=['Koopa Troopa']);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling"
      ],
      "metadata": {
        "id": "nZFVXw2_VGUG"
      },
      "id": "nZFVXw2_VGUG"
    },
    {
      "cell_type": "code",
      "source": [
        "# check df.min(), df.max()"
      ],
      "metadata": {
        "id": "CqxULbnjXMIc"
      },
      "id": "CqxULbnjXMIc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # standardize feature (whatever you do for X_train, do for X_test)\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# feat = str(X_train._get_numeric_data().idxmax(1)[0])\n",
        "# scaler = StandardScaler()\n",
        "# X_train[feat] = scaler.fit_transform(X_train[[feat]].values)\n",
        "# X_test[feat] = scaler.fit_transform(X_test[[feat]].values)"
      ],
      "metadata": {
        "id": "89-9bEl-QcYq"
      },
      "id": "89-9bEl-QcYq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # normalize feature (whatever you do for X_train, do for X_test)\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# feat = str(X_train._get_numeric_data().idxmax(1)[0])\n",
        "# scaler = MinMaxScaler()\n",
        "# X_train[feat] = scaler.fit_transform(X_train[[feat]].values)\n",
        "# X_test[feat] = scaler.fit_transform(X_test[[feat]].values)"
      ],
      "metadata": {
        "id": "Le8WNAHhXC1B"
      },
      "id": "Le8WNAHhXC1B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "840fa7c0",
      "metadata": {
        "id": "840fa7c0"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interesting Stats?"
      ],
      "metadata": {
        "id": "FqSMCL1zVba1"
      },
      "id": "FqSMCL1zVba1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interesting Visuals?"
      ],
      "metadata": {
        "id": "FN-sGpo8Ve56"
      },
      "id": "FN-sGpo8Ve56"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What's the Story?\n",
        "\n",
        "* https://en.wikipedia.org/wiki/Mario_Kart"
      ],
      "metadata": {
        "id": "Xvi3ADpeVU2-"
      },
      "id": "Xvi3ADpeVU2-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf423b5d",
      "metadata": {
        "id": "bf423b5d"
      },
      "outputs": [],
      "source": [
        "# # describe\n",
        "# X_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235da52d",
      "metadata": {
        "id": "235da52d"
      },
      "source": [
        "## Correlation\n",
        "\n",
        "* Correlation heat map\n",
        "* Correlation with code\n",
        "* Variance Threshold\n",
        "* Variance Inflation Factor\n",
        "* Removing Multicollinearity and Re Imaging\n",
        "* Re-enginnering Multicollinearity Features\n",
        "\n",
        "**SEE CORRELATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17fb2da2",
      "metadata": {
        "id": "17fb2da2"
      },
      "source": [
        "### Correlation and the Gradient\n",
        "\n",
        "* If the standard deviation for x and y are the same then the gradient is Pearson's correlation\n",
        "* **PEARSON's R and the GRADIENT**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68556ab3",
      "metadata": {
        "id": "68556ab3"
      },
      "source": [
        "### Multicollinearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df9f9a14",
      "metadata": {
        "id": "df9f9a14"
      },
      "outputs": [],
      "source": [
        "# # correlation heat map\n",
        "# import numpy as np\n",
        "# import seaborn as sns\n",
        "# from scipy import stats\n",
        "\n",
        "# # correlation matrix\n",
        "# sns.set(style=\"white\")\n",
        "\n",
        "# # compute the correlation matrix\n",
        "# corr = X_train.corr()\n",
        "\n",
        "# # generate a mask for the upper triangle\n",
        "# mask = np.zeros_like(corr, dtype=bool)\n",
        "# mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# # set up the matplotlib figure\n",
        "# # f, ax = plt.subplots()\n",
        "# f = plt.figure(figsize=(8, 8))\n",
        "\n",
        "# # generate a custom diverging colormap\n",
        "# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# # draw the heatmap with the mask and correct aspect ratio\n",
        "# sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True);\n",
        "\n",
        "# plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f28a678",
      "metadata": {
        "id": "5f28a678"
      },
      "outputs": [],
      "source": [
        "# # delete one of the features out of the pair(s) that show multicollinearity\n",
        "# # whatever you do for X_train, do for X_test\n",
        "# X_train.drop(['Mii', 'Donkey Kong'], axis=1, inplace=True)\n",
        "# X_test.drop(['Mii', 'Donkey Kong'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5ff0872",
      "metadata": {
        "id": "b5ff0872"
      },
      "outputs": [],
      "source": [
        "# # sns pairplot\n",
        "# import seaborn as sns\n",
        "\n",
        "# eda_data = X_train.copy()\n",
        "# eda_data['Mario Kart'] = y_train\n",
        "\n",
        "# sns.pairplot(data=eda_data, corner=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac54182",
      "metadata": {
        "id": "bac54182"
      },
      "outputs": [],
      "source": [
        "# # scatter plots showing correlation\n",
        "# import pandas as pd\n",
        "# import seaborn as sns\n",
        "\n",
        "# sns.pairplot(data=eda_data, x_vars=['Toad', 'Isabelle', 'Koopa Troopa', 'Mario'], y_vars='Mario Kart',\n",
        "#              kind='reg',\n",
        "#              height=5,\n",
        "#              aspect=0.8,\n",
        "#              plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.5}});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c32dc3f",
      "metadata": {
        "id": "5c32dc3f"
      },
      "outputs": [],
      "source": [
        "# # correlation with target\n",
        "# X_train.corrwith(y_train).plot.bar(\n",
        "#         title = 'Correlation with Final Grade (Target)', rot = 45, grid = True);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a4c1fba",
      "metadata": {
        "id": "9a4c1fba"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fe6160e",
      "metadata": {
        "id": "5fe6160e"
      },
      "source": [
        "### Bi-Label Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69946260",
      "metadata": {
        "id": "69946260"
      },
      "outputs": [],
      "source": [
        "# # bi-label mapping\n",
        "# # whatever you do for X_train, do for X_test\n",
        "# X_train['Inkling'] = X_train['Inkling'].map({'up':1,'down':0})\n",
        "# X_test['Inkling'] = X_test['Inkling'].map({'up':1,'down':0})\n",
        "\n",
        "# X_train['King Boo'] = X_train['King Boo'].map({'yes':1,'no':0})\n",
        "# X_test['King Boo'] = X_test['King Boo'].map({'yes':1,'no':0})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0deb8836",
      "metadata": {
        "id": "0deb8836"
      },
      "source": [
        "### One-Hot Encoding\n",
        "\n",
        "#### Dummy Trap\n",
        "\n",
        "The dummy variable trap is a scenario in which the independent variables become multicollinear after addition of dummy variables. The value of one variable can be predicted from the values of other variable(s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd04552a",
      "metadata": {
        "id": "fd04552a"
      },
      "outputs": [],
      "source": [
        "# # use sklearn one hot encoder\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ohe = OneHotEncoder(categories='auto', drop='first', sparse=False, handle_unknown='ignore')\n",
        "\n",
        "# cat_features = ['Wario', 'Cat Peach']\n",
        "# ohe_train = ohe.fit_transform(X_train[cat_features])\n",
        "# ohe_train = pd.DataFrame(ohe_train, columns=ohe.get_feature_names_out(cat_features))\n",
        "# ohe_train.index = X_train.index\n",
        "# X_train = X_train.join(ohe_train)\n",
        "# X_train.drop(cat_features, axis=1, inplace=True)\n",
        "\n",
        "# ohe_test = ohe.transform(X_test[cat_features])\n",
        "# ohe_test = pd.DataFrame(ohe_test, columns=ohe.get_feature_names_out(cat_features))\n",
        "# ohe_test.index = X_test.index\n",
        "# X_test = X_test.join(ohe_test)\n",
        "# X_test.drop(cat_features, axis=1, inplace=True)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)\n",
        "# print(X_train.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57715b14",
      "metadata": {
        "id": "57715b14"
      },
      "source": [
        "### One-Hot Encoding Alternatives\n",
        "\n",
        "* Frequency Encoding\n",
        "* Mean Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089e0105",
      "metadata": {
        "id": "089e0105"
      },
      "outputs": [],
      "source": [
        "# # identify features with more than 5 features and use frequency encoding\n",
        "# freq_feats = []\n",
        "\n",
        "# for feat in freq_feats:\n",
        "#     freq = X_train.groupby(feat).size()/len(X_train)\n",
        "#     X_train.loc[:, feat] = X_train[feat].map(freq)\n",
        "#     freq = X_test.groupby(feat).size()/len(X_test)\n",
        "#     X_test.loc[:, feat] = X_test[feat].map(freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0011692",
      "metadata": {
        "id": "d0011692"
      },
      "source": [
        "## Metrics\n",
        "\n",
        "###  MSE\n",
        "\n",
        "$\\frac{1}{n}\\sum(y-\\hat{y})^2$\n",
        "\n",
        "vs.\n",
        "\n",
        "### Variance (sample)\n",
        "\n",
        "$\\frac{1}{n-1}\\sum(x-\\bar{x})^2$\n",
        "\n",
        "In statistics, the mean squared error (MSE) or mean squared deviation (MSD) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors—that is, the average squared difference between the estimated values and the actual value. MSE is a risk function, corresponding to the expected value of the squared error loss. The fact that MSE is almost always strictly positive (and not zero) is because of randomness or because the estimator does not account for information that could produce a more accurate estimate... The MSE can be written as the sum of the variance of the estimator and the squared bias of the estimator, providing a useful way to calculate the MSE and implying that in the case of unbiased estimators, the MSE and variance are equivalent.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Mean_squared_error\n",
        "\n",
        "In datasets with a small spread all values are very close to the mean, resulting in a small variance and standard deviation. Where a dataset is more dispersed, values are spread further away from the mean, leading to a larger variance and standard deviation.\n",
        "\n",
        "https://www.abs.gov.au/websitedbs/D3310114.nsf/home/statistical+language+-+measures+of+spread\n",
        "\n",
        "### R Squared\n",
        "\n",
        "* $SS_{res} = \\sum{(y - \\hat{y})^2}$\n",
        "* $SS_{tot} = \\sum{(y - \\bar{y})^2}$\n",
        "* $R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$\n",
        "\n",
        "In statistics, the Pearson correlation coefficient ― also known as Pearson's r ― is a measure of linear correlation between two sets of data. It is the ratio between the covariance of two variables and the product of their standard deviations; thus it is essentially a normalized measurement of the covariance, such that the result always has a value between −1 and 1. As with covariance itself, the measure can only reflect a linear correlation of variables, and ignores many other types of relationship or correlation. As a simple example, one would expect the age and height of a sample of teenagers from a high school to have a Pearson correlation coefficient significantly greater than 0, but less than 1 (as 1 would represent an unrealistically perfect correlation).\n",
        "\n",
        "https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
        "\n",
        "In statistics, the coefficient of determination, denoted R2 or r2 and pronounced \"R squared\", is the proportion of the variation in the dependent variable that is predictable from the independent variable(s).\n",
        "\n",
        "https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
        "\n",
        "* r shows correlation between x and y\n",
        "* r squared shows strength of model, the proportion of the variance y that can be explained by X in a linear regression model\n",
        "* **R-Squared, R, r, TSS ESS and RSS**\n",
        "\n",
        "### Adjusted R Squared\n",
        "\n",
        "Features are considered\n",
        "\n",
        "* $Adj R^2 = 1 - (1 - R^2)\\frac{n-1}{n-p-1}$ where p = number of features and n = size of dataset\n",
        "* $R^2$ will never decrease adding more features\n",
        "* Adj R squared accounts for relevant features\n",
        "* Adjusted $R^2$ will be influenced by an increase of $p$\n",
        "\n",
        "### MSE or R Squared\n",
        "\n",
        "It is recommended to use R-Squared or rather adjusted R-Squared for evaluating the model performance of the regression models. This is primarily because R-Squared captures the fraction of variance of actual values captured by the regression model and tends to give a better picture of the quality of the regression model. Also, MSE values differ based on whether the values of the response variable are scaled or not. A better measure instead of MSE is the root mean squared error (RMSE) which takes care of the fact related to whether the values of the response variable are scaled or not.\n",
        "\n",
        "https://vitalflux.com/mean-square-error-r-squared-which-one-to-use/\n",
        "\n",
        "### Cost or Loss Function\n",
        "\n",
        "In mathematical optimization and decision theory, a loss function or cost function (sometimes also called an error function) is a function that maps an event or values of one or more variables onto a real number intuitively representing some \"cost\" associated with the event. An optimization problem seeks to minimize a loss function. An objective function is either a loss function or its opposite (in specific domains, variously called a reward function, a profit function, a utility function, a fitness function, etc.), in which case it is to be maximized.\n",
        "\n",
        "We often use MSE as our cost function in linear regression $mse = \\frac{\\sum(y-\\hat{y})^2}{n}$.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Loss_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4016cd78",
      "metadata": {
        "scrolled": false,
        "id": "4016cd78",
        "outputId": "1a3381cc-9b31-41a4-d9b7-c441579b1c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean of our data is 0.02.\n"
          ]
        }
      ],
      "source": [
        "# visualizing deviations from the mean squared\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats.distributions import norm\n",
        "\n",
        "data = norm.rvs(size=10000)\n",
        "x = sorted(np.array(data))\n",
        "y = [(i - np.mean(x))**2 for i in x]\n",
        "plt.title('Squared Deviations')\n",
        "plt.plot(x, y)\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(f'The mean of our data is {round(np.mean(data), 2)}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9216cbf",
      "metadata": {
        "id": "f9216cbf"
      },
      "source": [
        "## Statsmodels and Ordinary Least Squares\n",
        "\n",
        "In statistics, ordinary least squares (OLS) is a type of linear least squares method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of explanatory variables by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being observed) in the given dataset and those predicted by the linear function of the independent variable.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Ordinary_least_squares\n",
        "\n",
        "## Adding a Constant (or Intercept)\n",
        "\n",
        "As a rule, the constant term is always included in the set of regressors X ...\n",
        "\n",
        "https://en.wikipedia.org/wiki/Ordinary_least_squares\n",
        "\n",
        "The intercept (often labeled the constant) is the expected mean value of y when all X=0.\n",
        "\n",
        "https://www.theanalysisfactor.com/interpreting-the-intercept-in-a-regression-model/\n",
        "\n",
        "Immediately above, we saw a key reason why you should include the constant in your regression model. It guarantees that your residuals have a mean of zero. Additionally, if you don’t include the constant, the regression line is forced to go through the origin. This means that all of the predictors and the response variable must equal zero at that point. If your fitted line doesn’t naturally go through the origin, your regression coefficients and predictions will be biased if you don't include the constant.\n",
        "\n",
        "https://blog.minitab.com/en/adventures-in-statistics-2/regression-analysis-how-to-interpret-the-constant-y-intercept"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21b03bcd",
      "metadata": {
        "id": "21b03bcd"
      },
      "outputs": [],
      "source": [
        "# # delete a bunch for\n",
        "# # whatever you do for X_train, do for X_test\n",
        "# drop_demo = ['Cat Peach_neutral',\n",
        "#               'Cat Peach_kind of disagree',\n",
        "#               'Cat Peach_kind of agree',\n",
        "#               'Cat Peach_disagree',\n",
        "#               'Wario_\\'slow\\'',\n",
        "#               'Wario_\\'medium\\'',\n",
        "#               'Chain Chomp',\n",
        "#               'Inkling'\n",
        "#              ]\n",
        "\n",
        "# X_train.drop(drop_demo, axis=1, inplace=True)\n",
        "# X_test.drop(drop_demo, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba7ee95",
      "metadata": {
        "id": "fba7ee95"
      },
      "outputs": [],
      "source": [
        "# import statsmodels.api as sm\n",
        "\n",
        "# # what ever we do for X_train, do for X_test\n",
        "# X_train.insert(0, 'const', 1)\n",
        "# X_test.insert(0, 'const', 1)\n",
        "# model = sm.OLS(y_train, X_train).fit()\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "009ce3f4",
      "metadata": {
        "id": "009ce3f4"
      },
      "source": [
        "### OLS Regression Results Explanation\n",
        "\n",
        "* Endog(enous): Similar to the dependent variable\n",
        "* Exog(enous): Similar to the independent variable\n",
        "* https://www.statisticshowto.com/endogenous-variable/\n",
        "* https://medium.com/swlh/interpreting-linear-regression-through-statsmodels-summary-4796d359035a\n",
        "\n",
        "### Model Info\n",
        "* Dep. Varialble: the response variable, dependent, outcome, etc.\n",
        "* Model: what model are we using (ordinary least squares) for the training\n",
        "* Method: how the parameters (coefficients) were calculated\n",
        "* No. Observations: the number of observations, rows... (n)\n",
        "* DF Residuals: degrees of freedom of the residuals\n",
        "* DF Model: number of parameters in the model excluding the constant if present\n",
        "* Covariance Type: deals with violations of assumptions\n",
        "\n",
        "### Goodness of Fit\n",
        "* R-Squared: coefficient of determination, how well the regression fits the data\n",
        "* Adj R-Squared: R-squared adjustment based on number of parameters and df residuals\n",
        "* F statistic: a measure of how significant the fit is\n",
        "* Prop F statistic: the probability that you would get the F stat given the null hypothesis\n",
        "* Log-Liklihood: can be used to compare the fit of different coefficients, the higher valur is better\n",
        "* AIC: Akaike Information Criterion is used to compare models, a lower score is better (doesn't address features, just the overall model)\n",
        "* BIC: Bayesian Information Criterion is similar to AIC but uses a higher penalty\n",
        "\n",
        "### Coefficients\n",
        "* coef: the estimated value of the coefficient\n",
        "* std error: the basic standard error of the estimate of the coefficient\n",
        "* t: the t-statistic value, how significant the coefficient is\n",
        "* P>|t|: the p-value, indicates a statistically significant relationship to the dependent variable if less than the confidence level, usually 0.05\n",
        "* 95% confidence interval: the lower and upper values\n",
        "\n",
        "### Statistical Tests\n",
        "* Skewness: A measure of the symmetry of the data about the mean\n",
        "* Kurtosis: A measure of the shape of the data\n",
        "* Omnibus: D'Angostino's test provides a combined test for the presence of skewness and kurtosis\n",
        "* Prob(Omnibus): probability of Omnibus\n",
        "* Jarque-Bera: Another test for skewness and kurtosis\n",
        "* Prob(Jarque-Bera): probability of Jarque-Bera\n",
        "* Durbin-Watson: A test for the presence of autocorrelation, if the errors aren't independent\n",
        "* Cond No: A test for multicollinearity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f34b1a6",
      "metadata": {
        "id": "5f34b1a6"
      },
      "source": [
        "## Stepwise Procedures\n",
        "\n",
        "* Backward Elimination: involves starting with all candidate variables, testing the deletion of each variable using a chosen model fit criterion, deleting the variable (if any) whose loss gives the most statistically insignificant deterioration of the model fit, and repeating this process until no further variables can be deleted without a statistically insignificant loss of fit.\n",
        "* Forward Selection: involves starting with no variables in the model, testing the addition of each variable using a chosen model fit criterion, adding the variable (if any) whose inclusion gives the most statistically significant improvement of the fit, and repeating this process until none improves the model to a statistically significant extent.\n",
        "* Mixed Selection: a combination of the above, testing at each step for variables to be included or excluded."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e161bcbc",
      "metadata": {
        "id": "e161bcbc"
      },
      "source": [
        "### Backward Elimination Process\n",
        "\n",
        "* Note Adj R-squared\n",
        "* AIC\n",
        "* BIC\n",
        "* Note P>|t| greater than 0.05\n",
        "\n",
        "Let's get rid of the feature with the highest P>|t| and run it again to see if anything improves\n",
        "\n",
        "**AIC**: The Akaike information criterion (AIC) is an estimator of prediction error and thereby relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. Thus, AIC provides a means for model selection.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Akaike_information_criterion\n",
        "\n",
        "**BIC**: In statistics, the Bayesian information criterion (BIC) or Schwarz information criterion (also SIC, SBC, SBIC) is a criterion for model selection among a finite set of models; models with lower BIC are generally preferred. It is based, in part, on the likelihood function and it is closely related to the Akaike information criterion (AIC).\n",
        "\n",
        "https://en.wikipedia.org/wiki/Bayesian_information_criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9da05092",
      "metadata": {
        "scrolled": false,
        "id": "9da05092"
      },
      "outputs": [],
      "source": [
        "# # review model summary\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91cecba",
      "metadata": {
        "id": "a91cecba"
      },
      "source": [
        "### Term Review\n",
        "\n",
        "### Const\n",
        "\n",
        "The constant, y intercept, takes care of the bias in the data (a constant difference which is there for all observations). Recall bias plot in Bessel's Correction, it forces the residuals to have that crucial zero mean.\n",
        "\n",
        "https://statisticsbyjim.com/regression/interpret-constant-y-intercept-regression/\n",
        "\n",
        "### Coefficient\n",
        "\n",
        "The standardized simple linear regression coefficient is equal to the correlation coefficient (r). In the OLS summary, the coefficient shows the amount y changes for a unit increase in x. In this way it represents the degree to which the line slopes upwards or downwards.\n",
        "\n",
        "### Standard Error\n",
        "\n",
        "The standard error of a coefficient indicates the accuracy of the estimated ordinary least squares (OLS) coefficient with respect to its population parameter. Each standard error is the square root of the variance of the corresponding coefficient.\n",
        "\n",
        "https://medium.com/swlh/interpreting-linear-regression-through-statsmodels-summary-4796d359035a\n",
        "\n",
        "### t - Statistic\n",
        "\n",
        "Dividing the coefficient by its standard error calculates a t-value. If the p-value associated with this t-statistic is less than your alpha level, you conclude that the coefficient is significantly different from zero.\n",
        "\n",
        "https://support.minitab.com/en-us/minitab/20/help-and-how-to/statistical-modeling/regression/supporting-topics/regression-models/what-is-the-standard-error-of-the-coefficient/\n",
        "\n",
        "Associated with a t-test such as in a test of means, the comparison of the means of two samples\n",
        "\n",
        "### P > |t|\n",
        "\n",
        "For each test, the t-value is a way to quantify the difference between the population means and the p-value is the probability of obtaining a t-value with an absolute value at least as large as the one we actually observed in the sample data if the null hypothesis is actually true.\n",
        "\n",
        "https://www.statology.org/t-value-vs-p-value/\n",
        "\n",
        "### .025 ~ .975\n",
        "\n",
        "Measurements of values of our coefficients within 95% of our data, or within two standard deviations. Outside of these values can generally be considered outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49f4b06a",
      "metadata": {
        "id": "49f4b06a"
      },
      "outputs": [],
      "source": [
        "# model = sm.OLS(y_train, X_train.drop(['King Boo'], axis=1)).fit()\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "306663c9",
      "metadata": {
        "id": "306663c9"
      },
      "outputs": [],
      "source": [
        "# model = sm.OLS(y_train, X_train.drop(['King Boo', 'Princess Peach'], axis=1)).fit()\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "245ed4b5",
      "metadata": {
        "id": "245ed4b5"
      },
      "source": [
        "### Forward Selection Process\n",
        "\n",
        "Start with the lowest alphas\n",
        "\n",
        "* Note Adj r-squared\n",
        "* AIC\n",
        "* BIC\n",
        "\n",
        "**AIC**: The Akaike information criterion (AIC) is an estimator of prediction error and thereby relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. Thus, AIC provides a means for model selection.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Akaike_information_criterion\n",
        "\n",
        "**BIC**: In statistics, the Bayesian information criterion (BIC) or Schwarz information criterion (also SIC, SBC, SBIC) is a criterion for model selection among a finite set of models; models with lower BIC are generally preferred. It is based, in part, on the likelihood function and it is closely related to the Akaike information criterion (AIC).\n",
        "\n",
        "https://en.wikipedia.org/wiki/Bayesian_information_criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5345723c",
      "metadata": {
        "id": "5345723c"
      },
      "outputs": [],
      "source": [
        "# # forward selection\n",
        "# model = sm.OLS(y_train, X_train[['Toad']]).fit()\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98aaf6cd",
      "metadata": {
        "id": "98aaf6cd"
      },
      "outputs": [],
      "source": [
        "# # forward selection\n",
        "# model = sm.OLS(y_train, X_train[['Toad', 'Isabelle']]).fit()\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73b2fd88",
      "metadata": {
        "id": "73b2fd88"
      },
      "source": [
        "AIC and BIC both are trending up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc51a40a",
      "metadata": {
        "id": "bc51a40a"
      },
      "source": [
        "## Regularization\n",
        "\n",
        "* Penalizes complex models to avoid overfitting\n",
        "* More on overfitting and underfitting next week\n",
        "\n",
        "https://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/\n",
        "\n",
        "In mathematics, statistics, finance, computer science, particularly in machine learning and inverse problems, regularization is the process of adding information in order to solve an ill-posed problem or to prevent overfitting. Regularization can be applied to objective functions in ill-posed optimization problems. The regularization term, or penalty, imposes a cost on the optimization function to make the optimal solution unique.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Regularization_(mathematics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8a620f6",
      "metadata": {
        "id": "b8a620f6"
      },
      "source": [
        "### Lasso / l1 Regularization\n",
        "\n",
        "* $\\alpha = \\sum|w_i|$\n",
        "* Forces weak features to have zero coefficients\n",
        "* Performs feature selection\n",
        "* Models can be unstable (coefficients fluctuate significantly on data changes with correlated features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78759f41",
      "metadata": {
        "id": "78759f41"
      },
      "outputs": [],
      "source": [
        "# # lasso example\n",
        "# from sklearn.linear_model import Lasso\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# X = scaler.fit_transform(X_train)\n",
        "# y = y_train\n",
        "# names = X_train.columns\n",
        "\n",
        "# lasso = Lasso(alpha=8)\n",
        "# lasso.fit(X, y)\n",
        "\n",
        "# d = {'Feature': names, 'Coeff': lasso.coef_}\n",
        "# lasso_df = pd.DataFrame(d)\n",
        "# print(lasso_df[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf8e5e1b",
      "metadata": {
        "id": "cf8e5e1b"
      },
      "source": [
        "### Selected Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50224eae",
      "metadata": {
        "id": "50224eae"
      },
      "outputs": [],
      "source": [
        "# # what ever you do for X_train do for X_test\n",
        "# X_train = X_train[selected_features]\n",
        "# X_test = X_test[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b178aecd",
      "metadata": {
        "id": "b178aecd"
      },
      "outputs": [],
      "source": [
        "# X_train.insert(0, 'const', 1)\n",
        "# X_test.insert(0, 'const', 1)\n",
        "# model = sm.OLS(y_train, X_train).fit()\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97a820f6",
      "metadata": {
        "id": "97a820f6"
      },
      "source": [
        "## Sklearn Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31956a4c",
      "metadata": {
        "id": "31956a4c"
      },
      "outputs": [],
      "source": [
        "# # create and train the model\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# model = LinearRegression()\n",
        "# model.fit(X_train.drop('const', axis=1), y_train)\n",
        "\n",
        "# # test set prediction results\n",
        "# yhat = model.predict(X_test.drop('const', axis=1))\n",
        "# print('r squared: ', model.score(X_train.drop('const', axis=1), y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e0d9334",
      "metadata": {
        "id": "1e0d9334"
      },
      "outputs": [],
      "source": [
        "# # view the coefficients and intercept\n",
        "# print(model.intercept_)\n",
        "# print(list(zip(X_train.drop('const', axis=1), model.coef_)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41ba2624",
      "metadata": {
        "id": "41ba2624"
      },
      "source": [
        "### Interpreting the Coefficient\n",
        "\n",
        "* **COEFFICIENT INTERPRETATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "912e7468",
      "metadata": {
        "id": "912e7468"
      },
      "source": [
        "## Confidence Intervals\n",
        "\n",
        "* In a normal distribution, the confidence interval represents the spread of values where the null hypothesis is true, usually 95% or two standard deviations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7986d5",
      "metadata": {
        "id": "cf7986d5"
      },
      "outputs": [],
      "source": [
        "# # scatter plots showing correlation\n",
        "# import pandas as pd\n",
        "# import seaborn as sns\n",
        "\n",
        "# sns.pairplot(data=eda_data, x_vars=X_train.drop('const', axis=1).columns, y_vars='Mario Kart',\n",
        "#              kind='reg',\n",
        "#              height=5,\n",
        "#              aspect=0.8,\n",
        "#              plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.5}});"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a7673a0",
      "metadata": {
        "id": "2a7673a0"
      },
      "source": [
        "The shaded red areas represent our 95% confidence intervals.\n",
        "\n",
        "* Confidence intervals tend to be wider the more variability in a distribution\n",
        "* Confidence intervals tend to be narrower the larger the sample size is\n",
        "* Confidence intervals tend to be narrower when our accuracy is higher\n",
        "\n",
        "Looking at the scatterplots, which of the features have linear characteristics? Which of the lines of best fit are closer to being parallel to the x axis?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab8bb893",
      "metadata": {
        "id": "ab8bb893"
      },
      "source": [
        "### Measures of Center, Spread, and Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d96ebef",
      "metadata": {
        "id": "7d96ebef"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# sns.regplot(data=eda_data, x='Isabelle', y='Mario Kart'); # recommended to not use ci with large data\n",
        "# plt.axvline(x=eda_data['Isabelle'].mean(), color='green')\n",
        "# plt.axhline(y=eda_data['Mario Kart'].mean(), color='green');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a4f77e8",
      "metadata": {
        "id": "3a4f77e8"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# X_train.drop('const', axis=1).hist()\n",
        "# plt.tight_layout();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7e69cd5",
      "metadata": {
        "id": "c7e69cd5"
      },
      "source": [
        "## Prediction Intervals\n",
        "\n",
        "You should use a prediction interval instead of a confidence intervals for predictions. Using the confidence interval will likely introduce error, meaning that values will fall outside that interval more often than you predict.\n",
        "\n",
        "Stephanie Glen. \"Prediction Interval: Simple Definition, Examples\" From StatisticsHowTo.com: Elementary Statistics for the rest of us! https://www.statisticshowto.com/prediction-interval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "127e8654",
      "metadata": {
        "id": "127e8654"
      },
      "outputs": [],
      "source": [
        "# # build OLS model and print summary\n",
        "# import statsmodels.api as sm\n",
        "\n",
        "# # eda_data.insert(0, 'const', 1)\n",
        "# intervals_model = sm.OLS(eda_data['Mario Kart'], eda_data['Isabelle'])\n",
        "# results = intervals_model.fit()\n",
        "# print(results.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "603c3c5b",
      "metadata": {
        "id": "603c3c5b"
      },
      "outputs": [],
      "source": [
        "# # make predictions\n",
        "# predictions = results.get_prediction(eda_data['Isabelle']).summary_frame(alpha=0.05)\n",
        "# predictions[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97a482a2",
      "metadata": {
        "scrolled": false,
        "id": "97a482a2"
      },
      "outputs": [],
      "source": [
        "# sns.regplot(x='Isabelle', y='Mario Kart',\n",
        "#             data=eda_data,\n",
        "#             scatter_kws={'color': 'blue', 'alpha': 0.5},\n",
        "#             label='observed',\n",
        "#             line_kws={'label': 'regression'},\n",
        "#             color='red')\n",
        "# plt.plot(eda_data['Isabelle'], predictions['obs_ci_upper'], label='prediction', color='green')\n",
        "# plt.plot(eda_data['Isabelle'], predictions['obs_ci_lower'], color='green')\n",
        "# plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e050c06",
      "metadata": {
        "id": "3e050c06"
      },
      "source": [
        "## Imputation Using Prediction\n",
        "\n",
        "* **IMPUTATION USING PREDICTION**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}