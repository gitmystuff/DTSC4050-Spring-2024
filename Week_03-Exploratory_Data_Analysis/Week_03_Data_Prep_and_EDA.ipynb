{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC4050/blob/main/Week_03-Exploratory_Data_Analysis/Week_03_Data_Prep_and_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "268ad749",
      "metadata": {
        "id": "268ad749"
      },
      "source": [
        "# Week 03 - Data Prep and Exploratory Data Analysis (EDA)\n",
        "\n",
        "Your Name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started\n",
        "\n",
        "* Colab - get notebook from gitmystuff DTSC4050 repository\n",
        "* Save a Copy in Drive\n",
        "* Remove Copy of\n",
        "* Edit name\n",
        "* Take attendance\n",
        "* Clean up Colab Notebooks folder\n",
        "* Submit shared link"
      ],
      "metadata": {
        "id": "ojyIDptwB7Iy"
      },
      "id": "ojyIDptwB7Iy"
    },
    {
      "cell_type": "markdown",
      "id": "c41cc0a6",
      "metadata": {
        "id": "c41cc0a6"
      },
      "source": [
        "## Functions, Methods, and Attributes\n",
        "\n",
        "* df.shape: attribute; values that are precomputed\n",
        "* df.head(): method; values are computed when called; belongs to a class, package, module, an object\n",
        "* my_func(): function; usually created by programmer; set of instructions that perform a task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec7572c3",
      "metadata": {
        "id": "ec7572c3"
      },
      "source": [
        "## Data Prep\n",
        "\n",
        "### More Data Resources\n",
        "\n",
        "* https://www.statsmodels.org/devel/datasets/index.html\n",
        "* https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research\n",
        "* http://lib.stat.cmu.edu/datasets/\n",
        "* https://www.kaggle.com/datasets\n",
        "* https://registry.opendata.aws/\n",
        "* https://dataportals.org/\n",
        "* https://opendatamonitor.eu/frontend/web/index.php?r=dashboard%2Findex\n",
        "* https://data.nasdaq.com/\n",
        "* http://radar.oreilly.com/2011/01/journalist-data-tools.html\n",
        "* https://www.reddit.com/r/datasets/\n",
        "* https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html\n",
        "* https://github.com/vincentarelbundock/Rdatasets\n",
        "* https://data.world/\n",
        "* https://data.gov/\n",
        "* https://registry.opendata.aws/\n",
        "* https://cloud.google.com/datasets\n",
        "* https://cloud.google.com/bigquery/public-data\n",
        "* https://services.google.com/fh/files/misc/public_datasets_one_pager.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Driven Decision Making\n",
        "\n",
        "* Von Neumann, Dr. Strangelove, and Game Theory\n",
        "* https://thecritic.co.uk/issues/february-2022/the-genius-that-was-dr-strangelove/\n",
        "* https://en.wikipedia.org/wiki/Theory_of_Games_and_Economic_Behavior\n",
        "* https://medium.com/@skueong/thinking-in-bets-making-smarter-decisions-when-you-dont-have-all-the-facts-book-notes-98f02db61c1a\n",
        "* Westley vs Vizzini and the poison drinks (The Princess Bride)\n",
        "* https://www.cbr.com/battle-of-wits-scene-sham-theory-princess-bride/\n",
        "* A lethal battle of wits, Thinking in Bets"
      ],
      "metadata": {
        "id": "l9c8XQVtqMEO"
      },
      "id": "l9c8XQVtqMEO"
    },
    {
      "cell_type": "markdown",
      "id": "0b50af6f",
      "metadata": {
        "id": "0b50af6f"
      },
      "source": [
        "### Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2078a7e2",
      "metadata": {
        "id": "2078a7e2"
      },
      "outputs": [],
      "source": [
        "# download class-grades from github and upload it to session storage\n",
        "# print shape, info, and first five rows\n",
        "# import pandas as pd\n",
        "\n",
        "# grades = pd.read_csv('class-grades.csv')\n",
        "# grades = pd.read_csv('class-grades2.csv', on_bad_lines='warn')\n",
        "# print(grades.shape)\n",
        "# print(grades.info())\n",
        "# grades.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "424776a2",
      "metadata": {
        "id": "424776a2"
      },
      "source": [
        "### Missing Values\n",
        "\n",
        "Missing data cause problems because most statistical procedures require a value for each variable. When a data set is incomplete, the data analyst has to decide how to deal with it.\n",
        "\n",
        "https://www.theanalysisfactor.com/causes-of-missing-data/<br />\n",
        "https://www.theanalysisfactor.com/when-listwise-deletion-works/\n",
        "\n",
        "* MCAR: Missing Completely at Random\n",
        "    * Probability of missing is same for all cases\n",
        "    * I tripped and broke the test tubes I was carrying\n",
        "    * Missing because not sampled\n",
        "* MNAR: Missing Not at Random\n",
        "    * Probability of missing is not the same for all cases\n",
        "    * Data are missing on IQ and only the people with low IQ values have missing observations for this variable\n",
        "    * Missing from public opinion because respondent maybe inhibited or have bias\n",
        "* MAR: Mising at Random\n",
        "    * Probability of missing is the same only within groups\n",
        "    * Probability of sample depends on some known property\n",
        "    * Only younger people have missing values for IQ\n",
        "\n",
        "https://stefvanbuuren.name/fimd/sec-MCAR.html<br />\n",
        "https://www.iriseekhout.com/post/2022-06-28-missingdatamechanisms/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80e59473",
      "metadata": {
        "id": "80e59473"
      },
      "source": [
        "### Complete-Case Analysis (CCA)\n",
        "\n",
        "* Aka Listwise deletion\n",
        "* Reduces sample size\n",
        "* Can reduce the statistical efficiency of estimates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69119af1",
      "metadata": {
        "id": "69119af1"
      },
      "outputs": [],
      "source": [
        "# delete rows with missing values\n",
        "# print(grades.shape)\n",
        "# print(grades.dropna().shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28b3cf11",
      "metadata": {
        "id": "28b3cf11"
      },
      "source": [
        "### Cardinality of Features\n",
        "* Uneven distribution of labels between train and test sets (some may appear in one set and not in other)\n",
        "* Features with many labels dominate over those with fewer labels\n",
        "* Many labels introduces noise with little or no information\n",
        "* Reducing may help model performance\n",
        "* Removing features with low cardinality my help model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3e472c",
      "metadata": {
        "id": "fe3e472c"
      },
      "outputs": [],
      "source": [
        "# features with only one value (constant)\n",
        "# constant_features = [\n",
        "#     feat for feat in grades.columns if len(grades[feat].unique()) == 1\n",
        "# ]\n",
        "\n",
        "# print(grades.shape)\n",
        "# constant_features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop constant_features\n",
        "# grades.drop(constant_features, axis=1, inplace=True)\n",
        "# print(grades.shape)"
      ],
      "metadata": {
        "id": "wAGTtjJGRxWT"
      },
      "id": "wAGTtjJGRxWT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e349fbd6",
      "metadata": {
        "id": "e349fbd6"
      },
      "outputs": [],
      "source": [
        "# identify quasi constant values (sometimes these may be boolean/binary features)\n",
        "# quasi_consts = []\n",
        "# for val in grades.columns.sort_values():\n",
        "#     if (len(grades[val].unique()) < 3):\n",
        "#         val_counts = grades[val].value_counts(normalize=True)\n",
        "#         print(val_counts)\n",
        "#         if list(val_counts)[0] > .98:\n",
        "#             quasi_consts.append(val)\n",
        "\n",
        "# print('quasi_consts', quasi_consts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop quasi_consts\n",
        "# grades.drop(quasi_consts, axis=1, inplace=True)\n",
        "# grades.shape"
      ],
      "metadata": {
        "id": "tNmlDtA8YVOu"
      },
      "id": "tNmlDtA8YVOu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f47e67d5",
      "metadata": {
        "id": "f47e67d5"
      },
      "source": [
        "### Duplications"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# duplicate rows\n",
        "# grades[grades.duplicated(keep=False)]"
      ],
      "metadata": {
        "id": "PQMmwlv9Lklw"
      },
      "id": "PQMmwlv9Lklw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicate rows\n",
        "# print(grades.shape)\n",
        "# grades.drop_duplicates(inplace=True)\n",
        "# grades.shape"
      ],
      "metadata": {
        "id": "0GIAZy6ALgC9"
      },
      "id": "0GIAZy6ALgC9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a511cc25",
      "metadata": {
        "id": "a511cc25"
      },
      "outputs": [],
      "source": [
        "# check of duplications\n",
        "# duplicated_feats = []\n",
        "# for i in range(0, len(grades.columns)):\n",
        "#     orig = grades.columns[i]\n",
        "\n",
        "#     for dupe in grades.columns[i + 1:]:\n",
        "#         if grades[orig].equals(grades[dupe]):\n",
        "#             duplicated_feats.append(dupe)\n",
        "\n",
        "# duplicated_feats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicated_feats\n",
        "# print(grades.shape)\n",
        "# grades.drop(duplicated_feats, axis=1, inplace=True)\n",
        "# grades.shape"
      ],
      "metadata": {
        "id": "BTG-Owb7XtbN"
      },
      "id": "BTG-Owb7XtbN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "89aaa3dd",
      "metadata": {
        "id": "89aaa3dd"
      },
      "source": [
        "### Any vs All"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a61d39",
      "metadata": {
        "id": "08a61d39"
      },
      "outputs": [],
      "source": [
        "# count nulls\n",
        "# grades.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d153c4e1",
      "metadata": {
        "id": "d153c4e1"
      },
      "outputs": [],
      "source": [
        "# drop columns with null values https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n",
        "# print(grades.shape)\n",
        "# grades.dropna(how='all', axis='columns', inplace=True) # 1\n",
        "# print(grades.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffce2927",
      "metadata": {
        "id": "ffce2927"
      },
      "outputs": [],
      "source": [
        "# drop rows with null values\n",
        "# print(grades.shape)\n",
        "# print(grades.dropna(how='any', axis='index').shape) # information is lost when we drop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f8961e4",
      "metadata": {
        "id": "7f8961e4"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descriptive Statistics\n",
        "\n",
        "* Descriptive statistics: the numbers and calculations we use to summarize raw data\n",
        "* The mean is prone to distortion by outliers so we have the median\n",
        "* Elon Musk and Tiny Homes, 35000 till Elon joins and then average income jumps to $91 million\n",
        "* Absolute statistic vs relative statistic\n",
        "* Standard deviation: how dispersed the data from the mean, how spread out\n",
        "* Descriptive statistics are often used to compare two quantities"
      ],
      "metadata": {
        "id": "2XRPz7hFQxFZ"
      },
      "id": "2XRPz7hFQxFZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anscombes Quartet\n",
        "Anscombe's quartet comprises four data sets that have nearly identical simple descriptive statistics, yet have very different distributions and appear very different when graphed.\n",
        "https://en.wikipedia.org/wiki/Anscombe%27s_quartet"
      ],
      "metadata": {
        "id": "5Coy4KF5p9ou"
      },
      "id": "5Coy4KF5p9ou"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deceptive Statitics\n",
        "\n",
        "* The use of statistics to describe complex phenomena is not exact\n",
        "* Again precision and accuracy\n",
        "* Precision can mask inaccuracy\n",
        "* In 1950, Joseph McCarthy waved a piece of paper in a speech and declared he had a list of 205 names known to the Secretary of State that were working in the State Department. The paper was blank and this was an outright lie, but the specificity gave the lie credibility\n",
        "* Measurements, or calculations, no matter how precise, need to be checked with common sense\n",
        "* Descriptive statistics may suffer from clarity over exactly what is being described\n",
        "* Be sure to present a range of statistics with a range of perspectives\n",
        "* Our schools are getting worse! 60% of our schools had lower test scores this year from last\n",
        "* Our schools are getting better! 80% of our students had higher test scores from last year\n",
        "* Not all schools/students are equal and it depends on the unit of analysis\n",
        "* One measured schools and the other measured students"
      ],
      "metadata": {
        "id": "5YNVj4ndqM8m"
      },
      "id": "5YNVj4ndqM8m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanatory Analysis vs Exploratory Analysis\n",
        "\n",
        "Exploratory analysis is the process of turning over 100 rocks to find perhaps 1 or 2 precious gemstones. Explanatory analysis is what happens when you have something specific you want to show an audience - probably about those 1 or 2 precious gemstones.\n",
        "\n",
        "https://www.storytellingwithdata.com/blog/2014/04/exploratory-vs-explanatory-analysis"
      ],
      "metadata": {
        "id": "Lflfw2QZZF_T"
      },
      "id": "Lflfw2QZZF_T"
    },
    {
      "cell_type": "markdown",
      "id": "11d57cbb",
      "metadata": {
        "id": "11d57cbb"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5abb17ad",
      "metadata": {
        "id": "5abb17ad"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(grades.drop('FinalGrade', axis=1), grades['FinalGrade'], test_size=.2, random_state=42)\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1f3e831",
      "metadata": {
        "id": "c1f3e831"
      },
      "outputs": [],
      "source": [
        "# info\n",
        "# X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "709bae64",
      "metadata": {
        "id": "709bae64"
      },
      "outputs": [],
      "source": [
        "# brief statistics\n",
        "# X_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "126d9d4d",
      "metadata": {
        "id": "126d9d4d"
      },
      "outputs": [],
      "source": [
        "# value counts\n",
        "# X_train['TakeHome'].str.lower().value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97707d53",
      "metadata": {
        "id": "97707d53"
      },
      "outputs": [],
      "source": [
        "# pie chart\n",
        "# grades['TakeHome'].str.lower().value_counts(dropna=False).plot.pie()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "541c8cbb",
      "metadata": {
        "id": "541c8cbb"
      },
      "outputs": [],
      "source": [
        "# show histograms\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# X_train.hist()\n",
        "# plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5eb588",
      "metadata": {
        "id": "6d5eb588"
      },
      "source": [
        "## Measures of Center\n",
        "* Mean\n",
        "* Median\n",
        "* Mode\n",
        "\n",
        "And the Normal Distribution: https://www.mathsisfun.com/data/standard-normal-distribution.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f55c153",
      "metadata": {
        "id": "5f55c153"
      },
      "outputs": [],
      "source": [
        "# mean, median, mode\n",
        "# import numpy as np\n",
        "\n",
        "# print('mean:', int(np.mean(X_train['Assignment1'])))\n",
        "# print('mean:', int(X_train['Assignment1'].mean()))\n",
        "# print('median:', int(X_train['Assignment1'].median()))\n",
        "# print('mode:', X_train['TakeHome'].mode())\n",
        "# print('mode:', X_train['TakeHome'].mode()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58dc35ef",
      "metadata": {
        "id": "58dc35ef"
      },
      "outputs": [],
      "source": [
        "# X_train['TakeHome'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what happens to the mean and median with skewed data\n",
        "# import numpy as np\n",
        "# from scipy.stats import skewnorm, norm\n",
        "# from scipy import stats\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# fig, ax = plt.subplots(1, 3, figsize=(14, 3))\n",
        "# skew = 20\n",
        "# n = 100000\n",
        "\n",
        "# r = skewnorm.rvs(skew, loc=0, scale=10, size=n)\n",
        "# ax[0].hist(r, bins=50, density=True, alpha=0.4)\n",
        "# ax[0].axvline(x=np.median(r), color='green', label='Median')\n",
        "# ax[0].axvline(x=np.mean(r).round(2), color='red', label='Mean')\n",
        "# ax[0].legend()\n",
        "# print(f'right skew data mean: {np.mean(r).round(2)}, median: {np.median(r).round(2)}')\n",
        "\n",
        "# l = skewnorm.rvs(-skew, loc=0, scale=10, size=n)\n",
        "# ax[2].hist(l, bins=50, density=True, alpha=0.4);\n",
        "# ax[2].axvline(x=np.mean(l).round(2), color='red', label='Mean')\n",
        "# ax[2].axvline(x=np.median(l), color='green', label='Median')\n",
        "# ax[2].legend()\n",
        "# print(f'left skew data mean: {np.mean(l).round(2)}, median: {np.median(l).round(2)}')\n",
        "\n",
        "# n = norm.rvs(loc=0, scale=1, size=n)\n",
        "# ax[1].hist(n, bins=50, density=True, alpha=0.4);\n",
        "# ax[1].axvline(x=np.mean(n).round(2), color='red', linewidth=3, label='Mean')\n",
        "# ax[1].axvline(x=np.median(n), color='green', label='Median')\n",
        "# ax[1].legend()\n",
        "# print(f'normal data mean: {np.mean(n).round(2)}, median: {np.median(n).round(2)}')"
      ],
      "metadata": {
        "id": "wy1B6u7voAHY"
      },
      "id": "wy1B6u7voAHY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d6ce6a16",
      "metadata": {
        "id": "d6ce6a16"
      },
      "source": [
        "### The Wisdom of the Crowd, The Median"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab67540",
      "metadata": {
        "id": "3ab67540"
      },
      "source": [
        "### Imputing Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03b7e654",
      "metadata": {
        "id": "03b7e654"
      },
      "outputs": [],
      "source": [
        "# X_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab0a59a6",
      "metadata": {
        "id": "ab0a59a6"
      },
      "outputs": [],
      "source": [
        "# replace missing values with mean\n",
        "# X_train['Assignment1'].fillna(X_train['Assignment1'].round(decimals=2).mean(), inplace=True)\n",
        "# X_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837cf897",
      "metadata": {
        "id": "837cf897"
      },
      "outputs": [],
      "source": [
        "# replace missing values for Tutorial, Midterm, Quiz, and Final using the example above"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b0572cc",
      "metadata": {
        "id": "2b0572cc"
      },
      "source": [
        "## Measures of Spread"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6e05e23",
      "metadata": {
        "id": "b6e05e23"
      },
      "source": [
        "### Variance\n",
        "\n",
        "Equation for mean:<br />\n",
        "$\\mu = \\frac{1}{N} \\sum_{i=1}^{N} x_i$\n",
        "\n",
        "https://www.statology.org/sample-variance-vs-population-variance/<br />\n",
        "Equation for population variance:<br />\n",
        "$\\sigma^2 = \\frac{1}{N}\\sum({x}-\\bar{x})^2$\n",
        "\n",
        "Equation for sample variance:<br />\n",
        "$s^2 = \\frac{1}{n-1}\\sum({x}-\\bar{x})^2$\n",
        "\n",
        "Equation for standard deviation:<br />\n",
        "$\\sigma = \\sqrt{\\frac{1}{N}\\sum(x-\\bar{x})^2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "246a6e16",
      "metadata": {
        "id": "246a6e16"
      },
      "outputs": [],
      "source": [
        "# Assignment variance and standard deviation\n",
        "# print('Population variance:', X_train['Final'].var(ddof=0))\n",
        "# print('Sample variance:', X_train['Final'].var(ddof=1))\n",
        "# print('Population std dev:', X_train['Final'].std(ddof=0))\n",
        "# print('Sample std dev:', X_train['Final'].std(ddof=1))\n",
        "# print('Square root of sample variance:', np.sqrt(X_train['Final'].var()))\n",
        "# print('Square root of sample variance:', X_train['Final'].var()**(1/2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747d0858",
      "metadata": {
        "id": "747d0858"
      },
      "source": [
        "### Quartiles\n",
        "\n",
        "https://en.wikipedia.org/wiki/Interquartile_range\n",
        "\n",
        "Interquartile range<br />\n",
        "Whiskers<br />\n",
        "\n",
        "Outliers<br />\n",
        "Fence<br />\n",
        "https://www.statisticshowto.com/upper-and-lower-fences/\n",
        "\n",
        "Boxplots<br />\n",
        "Violin plots"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Percentages\n",
        "\n",
        "* Naked Statistics - the dress and 25% markdown\n",
        "* Art of Statistics Chapter 2 - 5% mortality sounds much worse than 95% survival"
      ],
      "metadata": {
        "id": "RJr1D1crQ3cJ"
      },
      "id": "RJr1D1crQ3cJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aa5b5b1",
      "metadata": {
        "id": "2aa5b5b1"
      },
      "outputs": [],
      "source": [
        "# Assignment histogram\n",
        "# X_train['Final'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2163a715",
      "metadata": {
        "id": "2163a715"
      },
      "outputs": [],
      "source": [
        "# Assignment boxplot\n",
        "# X_train.boxplot(column=['Final']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "304660b6",
      "metadata": {
        "id": "304660b6"
      },
      "outputs": [],
      "source": [
        "# Assignment violinplot\n",
        "# import seaborn as sns\n",
        "\n",
        "# sns.violinplot(x=X_train['Final']);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "094c027a",
      "metadata": {
        "id": "094c027a"
      },
      "source": [
        "## Measures of Shape\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2021/05/shape-of-data-skewness-and-kurtosis/\n",
        "\n",
        "**Skewness**\n",
        "* Skewed right\n",
        "* Skewed left\n",
        "\n",
        "**Kurtosis**\n",
        "* Mesokurtic\n",
        "* Leptokurtic\n",
        "* Platykurtic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59d3bd9c",
      "metadata": {
        "id": "59d3bd9c"
      },
      "outputs": [],
      "source": [
        "# visualize outliers before and after\n",
        "# from random import random\n",
        "# from random import randint\n",
        "# from sklearn.datasets import make_regression\n",
        "\n",
        "# X, y = make_regression(n_samples=100, n_features=1, noise=50, random_state=42)\n",
        "# print('mean before outliers:', np.mean(X))\n",
        "# print('var before outliers:', np.var(X))\n",
        "# fig, ([ax1, ax2], [ax3, ax4]) = plt.subplots(2, 2, figsize=(10, 10))\n",
        "# ax1.scatter(X, y)\n",
        "# ax2.hist(X)\n",
        "# ax3.boxplot(X)\n",
        "# sns.violinplot(ax=ax4, data=X);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0b0a4e",
      "metadata": {
        "id": "7d0b0a4e"
      },
      "outputs": [],
      "source": [
        "# create outliers\n",
        "# for i in range(30):\n",
        "#     factor = randint(-3, 3)\n",
        "#     if random() > 0.5:\n",
        "#         X[i] += factor * X.std()\n",
        "#     else:\n",
        "#         X[i] -= factor * X.std()\n",
        "\n",
        "# fig, ([ax1, ax2], [ax3, ax4]) = plt.subplots(2, 2, figsize=(10, 10))\n",
        "# ax1.scatter(X, y)\n",
        "# ax2.hist(X)\n",
        "# ax3.boxplot(X)\n",
        "# sns.violinplot(ax=ax4, data=X)\n",
        "# print('mean after outliers:', np.mean(X))\n",
        "# print('var after outliers:', np.var(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1cbf3d7",
      "metadata": {
        "id": "f1cbf3d7"
      },
      "source": [
        "### Skewed data\n",
        "\n",
        "https://www.itl.nist.gov/div898/handbook/eda/section3/eda33e6.htm\n",
        "\n",
        "Occur due to upper or lower bounds on the data<br />\n",
        "https://www.mathsisfun.com/definitions/upper-bound.html<br />\n",
        "Mean, Median, and Mode should be mentioned because there is no center in the usual sense<br />\n",
        "\n",
        "**Right Skewed**\n",
        "* Tail is on the right side\n",
        "* Mode Median Mean\n",
        "* Data have a lower bound\n",
        "\n",
        "**Left Skewed**\n",
        "* Tail is on the left\n",
        "* Mean Median Mode\n",
        "* Data have an upper bound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61543d9b",
      "metadata": {
        "id": "61543d9b"
      },
      "outputs": [],
      "source": [
        "# creating skewed data\n",
        "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skewnorm.html\n",
        "# from scipy.stats import skewnorm\n",
        "\n",
        "# a = 4 # skewness parameter: positive values are right skewed, negative values are left skewed\n",
        "# X = skewnorm.rvs(a, size=100)\n",
        "# fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 5))\n",
        "# ax1.hist(X)\n",
        "# ax2.boxplot(X)\n",
        "# sns.violinplot(ax=ax3, data=X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37d57f7f",
      "metadata": {
        "id": "37d57f7f"
      },
      "source": [
        "### Kurtosis\n",
        "\n",
        "https://www.investopedia.com/terms/p/platykurtic.asp\n",
        "\n",
        "* Mesokurtic: Extreme events are rare, resembles normal distribution\n",
        "* Platykurtic: Excess kurtosis is negative (< 3) and has thinner tails. Fewer extreme events. In finance, risk-averse investors might perfer platykurtic distributions\n",
        "* Leptokurtic: Excess kurtosis is greater than 3 and has fatter tails. Caused by extreme events or outliers.\n",
        "\n",
        "According to Investopedia (2022):\n",
        "\n",
        "> Risk-seeking investors can focus on investments whose returns follow a leptokurtic distribution, to maximize the chances of rare events—both positive and negative (para 3).\n",
        "\n",
        "Sources:\n",
        "* Leptokurtic Definition. (2022, February 1). In *Investopedia*. https://www.investopedia.com/terms/l/leptokurtic.asp.\n",
        "* https://medium.com/@filip.sekan/4-ways-how-to-shape-histograms-appearance-a87764df1417\n",
        "* https://miro.medium.com/v2/resize:fit:1100/format:webp/1*m2X-C-IMcYORq7G5mzvAzg.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf37501c",
      "metadata": {
        "id": "bf37501c"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from scipy.stats import norm\n",
        "\n",
        "# # generate a normal distribution\n",
        "# normal_dist = norm(0, 1)\n",
        "# normal_samples = normal_dist.rvs(10000)\n",
        "\n",
        "# # generate a leptokurtic distribution\n",
        "# leptokurtic_dist = norm(loc=0, scale=0.5)\n",
        "# leptokurtic_samples = leptokurtic_dist.rvs(10000)\n",
        "\n",
        "# # generate a platykurtic distribution\n",
        "# platykurtic_samples = normal_samples + np.random.randn(10000)\n",
        "\n",
        "# # Plot the distributions\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.hist(normal_samples, bins=100, alpha=0.5, label='Normal distribution')\n",
        "# plt.hist(leptokurtic_samples, bins=100, alpha=0.5, label='Leptokurtic distribution')\n",
        "# plt.hist(platykurtic_samples, bins=100, alpha=0.5, label='Platykurtic distribution')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c052ccd",
      "metadata": {
        "id": "4c052ccd"
      },
      "source": [
        "https://www.kaggle.com/getting-started/170781\n",
        "\n",
        "Skewness essentially measures the symmetry of the distribution, while kurtosis determines the heaviness of the distribution tails.\n",
        "\n",
        "The topic of Kurtosis has been controversial for decades now, the basis of kurtosis all these years has been linked with the peakedness but the ultimate verdict is that outliers (fatter tails) govern the kurtosis effect far more than the values near the mean (peak).\n",
        "\n",
        "https://towardsdatascience.com/skewness-kurtosis-simplified-1338e094fc85"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0327526",
      "metadata": {
        "id": "e0327526"
      },
      "source": [
        "### Moments\n",
        "\n",
        "According to Wikipedia (2022):\n",
        "\n",
        ">  If the function is a probability distribution, then the first moment is the expected value, the second central moment is the variance, the third standardized moment is the skewness, and the fourth standardized moment is the kurtosis (para 1).\n",
        "\n",
        "Moment (mathematics). (2022, January 31). In *Wikipedia*. https://en.wikipedia.org/wiki/Moment_(mathematics).\n",
        "\n",
        "Mean:<br />\n",
        "$\\mu = \\frac{1}{N} \\sum_{i=1}^{N} x_i$v\n",
        "\n",
        "Variance:<br />\n",
        "$s^2 = \\frac{\\sum(x-\\bar{x})^2}{n-1}$\n",
        "\n",
        "Skewness:<br />\n",
        "$\\frac{\\frac{1}{n}\\sum(x - \\mu)^3}{\\sigma^3}$\n",
        "\n",
        "Kurtosis:<br />\n",
        "$\\frac{\\frac{1}{n}\\sum(x - \\mu)^4}{\\sigma^4}$\n",
        "\n",
        "More reading: https://gregorygundersen.com/blog/2020/04/11/moments/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3713892",
      "metadata": {
        "id": "d3713892"
      },
      "source": [
        "## Correlation\n",
        "\n",
        "According to Wikipedia (2022):\n",
        "\n",
        ">  In statistics, correlation or dependence is any statistical relationship, whether causal or not, between two random variables or bivariate data. In the broadest sense correlation is any statistical association, though it actually refers to the degree to which a pair of variables are linearly related. Familiar examples of dependent phenomena include the correlation between the height of parents and their offspring, and the correlation between the price of a good and the quantity the consumers are willing to purchase... Correlations - 2 are useful because they can indicate a predictive relationship that can be exploited in practice (paras. 1 - 2).\n",
        "\n",
        "Correlation. (2022, February 1). In *Wikipedia*. https://en.wikipedia.org/wiki/Correlation.\n",
        "\n",
        "Correlation does not cause causation. Warm days on the beach, ice cream, and shark bites.\n",
        "\n",
        "Covariance:<br />\n",
        "$cov(x, y) = \\frac{1}{N} \\sum_{i=1}^{N}(x_i - \\bar{x}) (y_i - \\bar{y})$\n",
        "\n",
        "* Shows how variables change together\n",
        "* A measure of correlation\n",
        "* Measures direction\n",
        "\n",
        "Pearson’s r (correlation coefficient):<br />\n",
        "$\\rho_{x,y} = \\frac{cov(x,y)}{\\sigma_x\\sigma_y} = \\frac{\\frac{1}{N}\\sum(x-\\bar{x})(y-\\bar{y})}{\\sqrt\\frac{\\sum(x-\\bar{x})^2}{N}\\sqrt\\frac{\\sum(y-\\bar{y})^2}{N}}  = \\frac{\\sum(x-\\bar{x})(y-\\bar{y})}{\\sqrt{\\sum(x-\\bar{x})^2}\\sqrt{\\sum(y-\\bar{y})^2}}$\n",
        "\n",
        "* Shows linear relationship between two continuous variables\n",
        "* How one variable changes as another variable changes\n",
        "* Measures both strength and direction\n",
        "\n",
        "Resources:\n",
        "\n",
        "* https://statistics.laerd.com/statistical-guides/pearson-correlation-coefficient-statistical-guide.php\n",
        "* https://www.mygreatlearning.com/blog/covariance-vs-correlation/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # show correlation between the features\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# # correlation matrix\n",
        "# sns.set(style=\"white\")\n",
        "\n",
        "# # compute the correlation matrix\n",
        "# corr = X_train().corr()\n",
        "\n",
        "# # generate a mask for the upper triangle\n",
        "# mask = np.zeros_like(corr, dtype=bool)\n",
        "# mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# # set up the matplotlib figure\n",
        "# # f, ax = plt.subplots()\n",
        "# f = plt.figure(figsize=(8, 8))\n",
        "\n",
        "# # generate a custom diverging colormap\n",
        "# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# # draw the heatmap with the mask and correct aspect ratio\n",
        "# sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True);\n",
        "\n",
        "# plt.tight_layout()"
      ],
      "metadata": {
        "id": "MR6JK8P3pdYi"
      },
      "id": "MR6JK8P3pdYi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c716c7d4",
      "metadata": {
        "id": "c716c7d4"
      },
      "outputs": [],
      "source": [
        "# showing correlation of multiple features with one target\n",
        "# X_train.corrwith(y_train, numeric_only=True).plot.bar(\n",
        "#         title = \"Correlation with Target\", fontsize = 15,\n",
        "#         rot = 45, grid = True);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multicollinearity\n",
        "The need to reduce multicollinearity depends on its severity and your primary goal for your regression model. Keep the following three points in mind:\n",
        "* The severity of the problems increases with the degree of the multicollinearity. Therefore, if you have only moderate multicollinearity, you may not need to resolve it.\n",
        "* Multicollinearity affects only the specific independent variables that are correlated. Therefore, if multicollinearity is not present for the independent variables that you are particularly interested in, you may not need to resolve it. Suppose your model contains the experimental variables of interest and some control variables. If high multicollinearity exists for the control variables but not the experimental variables, then you can interpret the experimental variables without problems.\n",
        "* Multicollinearity affects the coefficients and p-values, but it does not influence the predictions, precision of the predictions, and the goodness-of-fit statistics. If your primary goal is to make predictions, and you don’t need to understand the role of each independent variable, you don’t need to reduce severe multicollinearity.\n",
        "https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/"
      ],
      "metadata": {
        "id": "2nlsDKEgpodc"
      },
      "id": "2nlsDKEgpodc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spurious Correlations\n",
        "\n",
        "* https://www.tylervigen.com/spurious-correlations"
      ],
      "metadata": {
        "id": "Z5qASGtTeEbJ"
      },
      "id": "Z5qASGtTeEbJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SweetViz\n",
        "\n",
        "* Pandas-Profiling\n",
        "* Autoviz\n",
        "* D-Tale\n",
        "* https://towardsdatascience.com/4-libraries-that-can-perform-eda-in-one-line-of-python-code-b13938a06ae\n",
        "* https://pypi.org/project/sweetviz/\n",
        "* https://colab.research.google.com/drive/1-md6YEwcVGWVnQWTBirQSYQYgdNoeSWg?usp=sharing"
      ],
      "metadata": {
        "id": "a7LoxB7pDknf"
      },
      "id": "a7LoxB7pDknf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Part I\n",
        "\n",
        "Presentations start next week\n",
        "\n",
        "* Think of a data science project you'd like to work on for the rest of the semester that uses a dataset\n",
        "* Think about a story you want to tell with this data\n",
        "* Introduce this dataset to the class and describe the dataset\n",
        "  * Train Test Datasets\n",
        "  * Shape, Info, Simple descriptives\n",
        "  * Missing values\n",
        "  * Histograms - Skewness Kurtosis\n",
        "  * Correlations\n",
        "\n",
        "Hints\n",
        "\n",
        "* Keep the dataset simple if possible\n",
        "* If you change your mind later, it's ok but a complete analysis as per the instructions in class will still be needed."
      ],
      "metadata": {
        "id": "sUkooZdnl7rp"
      },
      "id": "sUkooZdnl7rp"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}