{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC4050/blob/main/Week_07-Feature_Selection/Week_07_Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "266d1f99",
      "metadata": {
        "id": "266d1f99"
      },
      "source": [
        "# Week 07 - Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started\n",
        "\n",
        "* Colab - get notebook from gitmystuff DTSC4050 repository\n",
        "* Save a Copy in Drive\n",
        "* Remove Copy of\n",
        "* Edit name\n",
        "* Take attendance\n",
        "* Clean up Colab Notebooks folder\n",
        "* Submit shared link"
      ],
      "metadata": {
        "id": "1EZkjEQHeMxg"
      },
      "id": "1EZkjEQHeMxg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scientists toss 350,757 coins to prove that coin tosses arenâ€™t 50/50\n",
        "\n",
        "* https://www.ladbible.com/news/science/scientists-coin-toss-not-50-50-theory-325921-20240221"
      ],
      "metadata": {
        "id": "VI7EfBpmeRN0"
      },
      "id": "VI7EfBpmeRN0"
    },
    {
      "cell_type": "markdown",
      "id": "16b8cf02",
      "metadata": {
        "id": "16b8cf02"
      },
      "source": [
        "## An Introduction to Statistical Learning\n",
        "\n",
        "* https://www.statlearning.com/\n",
        "* https://github.com/JWarmenhoven/ISLR-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35dc6958",
      "metadata": {
        "id": "35dc6958"
      },
      "source": [
        "## Feature Selection\n",
        "\n",
        "https://www.datasciencesmachinelearning.com/2019/10/feature-selection-filter-method-wrapper.html\n",
        "\n",
        "* Filter Methods: Uses metrics such as correlation\n",
        "* Wrapper Methods: Uses predictive algorithms to predictive power\n",
        "* Embedded Methods: Selects features during model building (Lasso, Ridge, etc.)\n",
        "* https://miro.medium.com/v2/resize:fit:1400/1*9h2qPmOJonbCdthfeVkuyg.jpeg\n",
        "* https://miro.medium.com/v2/resize:fit:1400/1*tzfWABEHK9-4SOaSl1mdRA.png"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41d01c17",
      "metadata": {
        "id": "41d01c17"
      },
      "source": [
        "## Filter Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c62bb56",
      "metadata": {
        "id": "1c62bb56"
      },
      "outputs": [],
      "source": [
        "# # https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
        "# import pandas as pd\n",
        "\n",
        "# grades = pd.read_csv('https://raw.githubusercontent.com/gitmystuff/Datasets/main/class-grades2.csv', on_bad_lines='warn')\n",
        "# print(grades.shape)\n",
        "# print(grades.info())\n",
        "# grades.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # features with only one value (constant)\n",
        "# constant_features = [\n",
        "#     feat for feat in grades.columns if len(grades[feat].unique()) == 1\n",
        "# ]\n",
        "\n",
        "# print(grades.shape)\n",
        "# constant_features"
      ],
      "metadata": {
        "id": "lNEx00CQFQus"
      },
      "id": "lNEx00CQFQus",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # drop constant_features\n",
        "# grades.drop(constant_features, axis=1, inplace=True)\n",
        "# print(grades.shape)"
      ],
      "metadata": {
        "id": "9F6QDW6HFWT2"
      },
      "id": "9F6QDW6HFWT2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # identify quasi constant values (sometimes these may be boolean/binary features)\n",
        "# quasi_consts = []\n",
        "# for val in grades.columns.sort_values():\n",
        "#     if (len(grades[val].unique()) < 3):\n",
        "#         val_counts = grades[val].value_counts(normalize=True)\n",
        "#         print(val_counts)\n",
        "#         if list(val_counts)[0] > .98:\n",
        "#             quasi_consts.append(val)\n",
        "\n",
        "# print('quasi_consts', quasi_consts)"
      ],
      "metadata": {
        "id": "Itwim-0VFYLL"
      },
      "id": "Itwim-0VFYLL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # drop quasi_consts\n",
        "# grades.drop(quasi_consts, axis=1, inplace=True)\n",
        "# grades.shape"
      ],
      "metadata": {
        "id": "07hOjGYoFbP2"
      },
      "id": "07hOjGYoFbP2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # duplicate rows\n",
        "# grades[grades.duplicated(keep=False)]"
      ],
      "metadata": {
        "id": "E-YQ3yfIFjDT"
      },
      "id": "E-YQ3yfIFjDT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # drop duplicate rows\n",
        "# print(grades.shape)\n",
        "# grades.drop_duplicates(inplace=True)\n",
        "# grades.shape"
      ],
      "metadata": {
        "id": "0SChAZkrFmWK"
      },
      "id": "0SChAZkrFmWK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # check of duplications\n",
        "# duplicated_feats = []\n",
        "# for i in range(0, len(grades.columns)):\n",
        "#     orig = grades.columns[i]\n",
        "\n",
        "#     for dupe in grades.columns[i + 1:]:\n",
        "#         if grades[orig].equals(grades[dupe]):\n",
        "#             duplicated_feats.append(dupe)\n",
        "\n",
        "# duplicated_feats"
      ],
      "metadata": {
        "id": "fBfMlFqCFqBw"
      },
      "id": "fBfMlFqCFqBw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # drop duplicated_feats\n",
        "# print(grades.shape)\n",
        "# grades.drop(duplicated_feats, axis=1, inplace=True)\n",
        "# grades.shape"
      ],
      "metadata": {
        "id": "7Gr5DMdiFuZr"
      },
      "id": "7Gr5DMdiFuZr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa7f374",
      "metadata": {
        "id": "afa7f374"
      },
      "outputs": [],
      "source": [
        "# # train test split\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(grades.drop('FinalGrade', axis=1), grades['FinalGrade'], test_size=.2, random_state=42)\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # print missing values, data types\n",
        "# X_train.info()"
      ],
      "metadata": {
        "id": "nVsn7tftGKO7"
      },
      "id": "nVsn7tftGKO7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # brief statistics\n",
        "# X_train.describe()"
      ],
      "metadata": {
        "id": "2B_rpxO8GQpR"
      },
      "id": "2B_rpxO8GQpR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "554e23d0",
      "metadata": {
        "id": "554e23d0"
      },
      "outputs": [],
      "source": [
        "# # look at the distributions\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# X_train.hist()\n",
        "# plt.tight_layout();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # get missing values\n",
        "# X_train.isnull().sum()"
      ],
      "metadata": {
        "id": "f3EKF88jGhD1"
      },
      "id": "f3EKF88jGhD1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6790174",
      "metadata": {
        "id": "b6790174"
      },
      "outputs": [],
      "source": [
        "# # fillna based on skewness https://www.statisticshowto.com/pearson-mode-skewness/\n",
        "# X_train['Assignment1'].fillna(X_train['Assignment1'].round(decimals=2).median(), inplace=True)\n",
        "# X_train['Tutorial'].fillna(X_train['Tutorial'].round(decimals=2).median(), inplace=True)\n",
        "# X_train['Midterm'].fillna(X_train['Midterm'].round(decimals=2).mean(), inplace=True)\n",
        "# X_train['Final'].fillna(X_train['Final'].round(decimals=2).mean(), inplace=True)\n",
        "# X_train['TakeHome'].fillna(X_train['TakeHome'].mode()[0], inplace=True)\n",
        "# X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beb32e32",
      "metadata": {
        "id": "beb32e32"
      },
      "outputs": [],
      "source": [
        "# # Whatever you do to X_train, don't forget to do to X_test, but use X_train data\n",
        "# X_test['Assignment1'].fillna(X_train['Assignment1'].round(decimals=2).median(), inplace=True)\n",
        "# X_test['Tutorial'].fillna(X_train['Tutorial'].round(decimals=2).median(), inplace=True)\n",
        "# X_test['Midterm'].fillna(X_train['Midterm'].round(decimals=2).mean(), inplace=True)\n",
        "# X_test['Final'].fillna(X_train['Final'].round(decimals=2).mean(), inplace=True)\n",
        "# X_test['TakeHome'].fillna(X_train['TakeHome'].mode()[0], inplace=True)\n",
        "# X_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # take care of objects\n",
        "# print(X_train['BiLabel'].value_counts())\n",
        "# print(X_train.TakeHome.value_counts())"
      ],
      "metadata": {
        "id": "YHmRih8EH-nm"
      },
      "id": "YHmRih8EH-nm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # map bi labels\n",
        "# X_train['BiLabel'] = X_train['BiLabel'].map({'pepper': 0, 'salt': 1})\n",
        "# X_test['BiLabel'] = X_test['BiLabel'].map({'pepper': 0, 'salt': 1})\n",
        "# X_train.info()"
      ],
      "metadata": {
        "id": "9SzrUukdIUKh"
      },
      "id": "9SzrUukdIUKh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # take care of TakeHome lowercase\n",
        "# X_train['TakeHome'] = X_train['TakeHome'].apply(lambda x: x.lower())\n",
        "# X_train['TakeHome'].value_counts()"
      ],
      "metadata": {
        "id": "CNQqVgkgIoxf"
      },
      "id": "CNQqVgkgIoxf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # get features with more than 5 features\n",
        "# freq_feats = []\n",
        "\n",
        "# for val in X_train.select_dtypes(include='object').columns.sort_values():\n",
        "#   if len(X_train[val].dropna().unique()) > 4:\n",
        "#     freq_feats.append(val)\n",
        "\n",
        "# print(freq_feats)"
      ],
      "metadata": {
        "id": "d9rbRAtbJgaK"
      },
      "id": "d9rbRAtbJgaK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for feat in freq_feats:\n",
        "#     freq = X_train.groupby(feat).size()/len(X_train)\n",
        "#     X_train[feat] = X_train[feat].map(freq)\n",
        "#     freq = X_test.groupby(feat).size()/len(X_test)\n",
        "#     X_test[feat] = X_test[feat].map(freq)\n",
        "\n",
        "# X_train.info()"
      ],
      "metadata": {
        "id": "u9pqlTdsKKuX"
      },
      "id": "u9pqlTdsKKuX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variance Threshold\n",
        "\n",
        "* Feature selector that removes all low-variance features."
      ],
      "metadata": {
        "id": "_XxYzJQ-Yw45"
      },
      "id": "_XxYzJQ-Yw45"
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/gitmystuff/Datasets/main/class-grades2.csv', on_bad_lines='warn')\n",
        "# X_train1, X_test1, y_train1, y_test1 = train_test_split(df.drop('FinalGrade', axis=1), df['FinalGrade'], test_size=.2, random_state=42)\n",
        "# print(X_train1.shape)\n",
        "# print(X_test1.shape)"
      ],
      "metadata": {
        "id": "tsZ4ekK2YoS8"
      },
      "id": "tsZ4ekK2YoS8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d94eade",
      "metadata": {
        "id": "7d94eade"
      },
      "outputs": [],
      "source": [
        "# # https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html\n",
        "# from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# varthresh = VarianceThreshold(threshold=0)\n",
        "# varthresh.fit(X_train1._get_numeric_data())\n",
        "\n",
        "# # print the variable names that have constant values, use ~ to exclude\n",
        "# print(X_train1._get_numeric_data().columns[~varthresh.get_support()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca5c2c4e",
      "metadata": {
        "id": "ca5c2c4e"
      },
      "outputs": [],
      "source": [
        "# # features to keep\n",
        "# feats_names = X_train1._get_numeric_data().columns[varthresh.get_support()]\n",
        "# feats_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop_feats = X_train1._get_numeric_data().columns[~varthresh.get_support()]\n",
        "# X_train1.drop(drop_feats, axis=1)"
      ],
      "metadata": {
        "id": "Kx3LrIjyboO2"
      },
      "id": "Kx3LrIjyboO2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7d7675d5",
      "metadata": {
        "id": "7d7675d5"
      },
      "source": [
        "### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407bc5a6",
      "metadata": {
        "id": "407bc5a6"
      },
      "outputs": [],
      "source": [
        "# # the heatmap\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# sns.set(style='white')\n",
        "\n",
        "# # compute the correlation matrix\n",
        "# corr = X_train.corr(method='pearson')\n",
        "\n",
        "# # generate a mask for the upper triangle\n",
        "# mask = np.zeros_like(corr, dtype=bool)\n",
        "# mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# # set up the matplotlib figure\n",
        "# f, ax = plt.subplots(figsize=(10,10))\n",
        "\n",
        "# # generate a custom diverging colormap\n",
        "# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# # draw the heatmap with the mask and correct aspect ratio\n",
        "# sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "#             square=True, linewidths=.5, cbar_kws={'shrink': .5}, annot=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "734ea071",
      "metadata": {
        "id": "734ea071"
      },
      "outputs": [],
      "source": [
        "# # scatterplot\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.scatter(X_train['Midterm'], X_train['Final']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02fa19d4",
      "metadata": {
        "id": "02fa19d4"
      },
      "outputs": [],
      "source": [
        "# # build a correlation matrix\n",
        "# cormat = X_train.corr()\n",
        "# cormat = cormat.abs().unstack()\n",
        "# cormat = cormat.sort_values(ascending=False)\n",
        "# cormat = cormat[cormat >= 0]\n",
        "# cormat = cormat[cormat < 1]\n",
        "# cormat = pd.DataFrame(cormat).reset_index()\n",
        "# cormat.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
        "# cormat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ba2d8c",
      "metadata": {
        "id": "02ba2d8c"
      },
      "outputs": [],
      "source": [
        "# # show correlation of X_train with y_train\n",
        "# X_train.corrwith(y_train).plot.bar(\n",
        "#         title = \"Correlation with Target\", fontsize = 15,\n",
        "#         rot = 45, grid = True);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32877394",
      "metadata": {
        "id": "32877394"
      },
      "source": [
        "### Dropping Highly Correlated Features\n",
        "\n",
        "* Feature with most missing values\n",
        "* Use an algorithm to find which has more predictive power"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11fc8452",
      "metadata": {
        "id": "11fc8452"
      },
      "source": [
        "### Variance Inflation Factor\n",
        "\n",
        "* Measures how much one predictor is influenced, or inflated, by the presence, or correlation, of another predictor\n",
        "* Quick measure of the contribution of a predictor to the standard error, the standard deviation of a sample, in regression\n",
        "\n",
        "https://www.statisticshowto.com/variance-inflation-factor/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed909945",
      "metadata": {
        "id": "ed909945"
      },
      "outputs": [],
      "source": [
        "# # vif\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# feats_interest = ['Assignment1', 'Tutorial', 'Midterm', 'Final', 'TakeHome']\n",
        "# vif_data = [variance_inflation_factor(X_train[feats_interest].values, i) for i in range(len(X_train[feats_interest].columns))]\n",
        "\n",
        "# d = {'feature': X_train[feats_interest].columns.values, 'vif': vif_data}\n",
        "# vif = pd.DataFrame(d)\n",
        "# vif"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # vif with some features removed\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# feats_interest = ['Midterm', 'TakeHome']\n",
        "# vif_data = [variance_inflation_factor(X_train[feats_interest].values, i) for i in range(len(X_train[feats_interest].columns))]\n",
        "\n",
        "# d = {'feature': X_train[feats_interest].columns.values, 'vif': vif_data}\n",
        "# vif = pd.DataFrame(d)\n",
        "# vif"
      ],
      "metadata": {
        "id": "PBdx5Yw4Nz1f"
      },
      "id": "PBdx5Yw4Nz1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b23e535f",
      "metadata": {
        "id": "b23e535f"
      },
      "source": [
        "### Mutual Information\n",
        "\n",
        "* Measures the mutual dependence on two variables\n",
        "* Persons r is linear where as MI measures non-linear relationships\n",
        "* How much information can be extracted from one variable by observing another variable\n",
        "* Note on discretized variables (categorical)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ce096e",
      "metadata": {
        "id": "f7ce096e"
      },
      "outputs": [],
      "source": [
        "# # obtain the mutual information values and select features\n",
        "# from sklearn.feature_selection import mutual_info_regression\n",
        "# from sklearn.feature_selection import SelectPercentile\n",
        "\n",
        "# mi = mutual_info_regression(X_train, y_train)\n",
        "# mi = pd.Series(mi)\n",
        "# mi.index = X_train.columns\n",
        "# mi.sort_values(ascending=False).plot.bar()\n",
        "# plt.ylabel('Mutual Information');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a066dda",
      "metadata": {
        "id": "8a066dda"
      },
      "outputs": [],
      "source": [
        "# # Select the features in the top percentile\n",
        "# mi_perc = SelectPercentile(mutual_info_regression, percentile=20).fit(X_train, y_train)\n",
        "# X_train.columns[mi_perc.get_support()]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}